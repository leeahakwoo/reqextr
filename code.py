# app.py

import streamlit as st
import re
import pandas as pd
from typing import List, Dict
import docx
from docx.document import Document
from docx.table import Table
from docx.text.paragraph import Paragraph
import io

# --- ë¡œì§ í´ë˜ìŠ¤ ---
class StreamlitDocxExtractor:
    """
    [ìµœì¢… ì™„ì„±ë³¸] ë“¤ì—¬ì“°ê¸° ìˆ˜ì¤€(Indentation)ì„ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì •í™•í•œ ê³„ì¸µ êµ¬ì¡°ë¥¼ íŒŒì•…í•˜ëŠ” í´ë˜ìŠ¤.
    """
    def __init__(self, business_code: str = "MFDS"):
        self.business_code = business_code

    def _generate_id(self, req_id: str, sequence: int) -> str:
        """ìš”êµ¬ì‚¬í•­ IDë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        req_type_code = "F" if req_id.startswith("FUN") else "Q"
        id_num_match = re.search(r'\d+', req_id)
        id_num = id_num_match.group(0) if id_num_match else "000"
        return f"REQ-{self.business_code}-{req_type_code}-{id_num}{sequence:03d}"

    def _get_all_paragraphs_in_order(self, doc: Document) -> List[Paragraph]:
        """ë¬¸ì„œì˜ ëª¨ë“  ë¬¸ë‹¨ ê°ì²´ë¥¼ í‘œ ì•ˆì˜ ë‚´ìš©ê¹Œì§€ í¬í•¨í•˜ì—¬ ìˆœì„œëŒ€ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        all_paragraphs = []
        for block in doc.element.body:
            if isinstance(block, docx.oxml.text.paragraph.CT_P):
                all_paragraphs.append(Paragraph(block, doc))
            elif isinstance(block, docx.oxml.table.CT_Tbl):
                table = Table(block, doc)
                for row in table.rows:
                    for cell in row.cells:
                        all_paragraphs.extend(cell.paragraphs)
        return all_paragraphs

    def _get_indentation_level(self, p: Paragraph) -> int:
        """ë¬¸ë‹¨ì˜ ë“¤ì—¬ì“°ê¸° ìˆ˜ì¤€ì„ ë°˜í™˜í•©ë‹ˆë‹¤. (Noneì¼ ê²½ìš° 0ìœ¼ë¡œ ì²˜ë¦¬)"""
        return p.paragraph_format.left_indent.pt if p.paragraph_format.left_indent else 0

    def _parse_details_from_paragraphs(self, paragraphs: List[Paragraph], req_id: str) -> List[Dict]:
        """
        [ìµœì¢… ë¡œì§] ë“¤ì—¬ì“°ê¸° ìˆ˜ì¤€ì„ ê¸°ë°˜ìœ¼ë¡œ ê³„ì¸µ êµ¬ì¡°ë¥¼ íŒŒì•…í•˜ì—¬ ìš”êµ¬ì‚¬í•­ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
        """
        final_requirements = []
        bfn_seq_counter = 1
        group_stack = []  # ê·¸ë£¹ ì œëª©ì„ ì €ì¥í•˜ëŠ” ìŠ¤íƒ

        for p in paragraphs:
            line = p.text.strip()
            if not line:
                continue

            # ë¸”ë¦¿ ìŠ¤íƒ€ì¼ì´ ì ìš©ëœ ë¬¸ë‹¨ë§Œ ì²˜ë¦¬
            if not (p.style and 'List' in p.style.name):
                continue
            
            level = self._get_indentation_level(p)
            
            # ìŠ¤íƒì˜ ë§ˆì§€ë§‰ ë ˆë²¨ë³´ë‹¤ í˜„ì¬ ë ˆë²¨ì´ ë” ê¹Šìœ¼ë©´, ìŠ¤íƒì€ ìœ ì§€
            # ìŠ¤íƒì˜ ë§ˆì§€ë§‰ ë ˆë²¨ê³¼ í˜„ì¬ ë ˆë²¨ì´ ê°™ê±°ë‚˜ ë” ì–•ìœ¼ë©´, ìƒìœ„ ê·¸ë£¹ìœ¼ë¡œ ëŒì•„ê°
            while group_stack and level <= group_stack[-1]['level']:
                group_stack.pop()

            # í˜„ì¬ ë¬¸ë‹¨ì´ ê·¸ë£¹ ì œëª©ì´ ë  ìˆ˜ ìˆìŒ
            group_stack.append({'title': line, 'level': level})

            # í˜„ì¬ ìŠ¤íƒì˜ ìµœìƒìœ„ ê·¸ë£¹(1ë ˆë²¨)
            top_group = group_stack[0]['title'] if group_stack else ""
            
            # í˜„ì¬ ë¬¸ë‹¨ì´ ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ (ìŠ¤íƒì— 2ê°œ ì´ìƒ ìŒ“ì˜€ê±°ë‚˜, 1ê°œë§Œ ìˆì–´ë„ ê·¸ ìì²´ê°€ ìš”êµ¬ì‚¬í•­)
            if group_stack:
                 final_requirements.append({
                    'ìš”êµ¬ì‚¬í•­ ê·¸ë£¹': top_group,
                    'ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ë‚´ìš©': line,
                    'ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ID': self._generate_id(req_id, bfn_seq_counter)
                })
                 bfn_seq_counter += 1

        return final_requirements


    def process(self, docx_file: io.BytesIO, level1_bullets: str, level2_bullets: str) -> pd.DataFrame:
        doc = docx.Document(docx_file)
        all_paragraphs = self._get_all_paragraphs_in_order(doc)
        
        block_markers = []
        for i, p in enumerate(all_paragraphs):
            if 'ìš”êµ¬ì‚¬í•­ ë¶„ë¥˜' in p.text:
                block_markers.append(i)
        
        st.info(f"ì´ {len(block_markers)}ê°œì˜ ìš”êµ¬ì‚¬í•­ ë¸”ë¡ ì‹œì‘ì ì„ ì‹ë³„í–ˆìŠµë‹ˆë‹¤.")
        if not block_markers:
            st.warning("ë¬¸ì„œì—ì„œ 'ìš”êµ¬ì‚¬í•­ ë¶„ë¥˜' í‚¤ì›Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        all_requirements = []
        for i, start_index in enumerate(block_markers):
            end_index = block_markers[i+1] if i + 1 < len(block_markers) else len(all_paragraphs)
            
            block_paragraphs = all_paragraphs[start_index:end_index]
            block_text = "\n".join([p.text for p in block_paragraphs])
            
            # SyntaxWarning í•´ê²°: Raw string ì‚¬ìš©
            req_id_match = re.search(r'ìš”êµ¬ì‚¬í•­ ê³ ìœ ë²ˆí˜¸\s+([A-Z]{3}-\d{3})', block_text)
            req_name_match = re.search(r'ìš”êµ¬ì‚¬í•­ ëª…ì¹­\s+(.+?)(?:\n|$)', block_text)

            if not req_id_match or not req_name_match: continue

            req_id, req_name = req_id_match.group(1).strip(), req_name_match.group(1).strip()
            
            details_start_index_offset = -1
            for j, p in enumerate(block_paragraphs):
                if 'ì„¸ë¶€ë‚´ìš©' in p.text:
                    details_start_index_offset = j + 1
                    break
            
            if details_start_index_offset != -1:
                details_paragraphs = block_paragraphs[details_start_index_offset:]
                # ë¸”ë¦¿ ë¬¸ì ì„¤ì •ì€ ë” ì´ìƒ í•„ìš” ì—†ìœ¼ë¯€ë¡œ ì „ë‹¬í•˜ì§€ ì•ŠìŒ
                parsed_reqs = self._parse_details_from_paragraphs(details_paragraphs, req_id)
                
                for req in parsed_reqs:
                    req['ìš”êµ¬ì‚¬í•­ ID (RFP ì›ì²œ)'] = req_id
                    req['ìš”êµ¬ì‚¬í•­ ëª…ì¹­ (RFP ì›ì²œ)'] = req_name
                all_requirements.extend(parsed_reqs)

        if not all_requirements:
            st.warning("ìš”êµ¬ì‚¬í•­ ë¸”ë¡ì€ ì°¾ì•˜ìœ¼ë‚˜, ì„¸ë¶€ ë‚´ìš©ì„ íŒŒì‹±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë¬¸ì„œì˜ 'ì„¸ë¶€ë‚´ìš©'ì— ê¸€ë¨¸ë¦¬ ê¸°í˜¸ ëª©ë¡ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return pd.DataFrame()

        df = pd.DataFrame(all_requirements)
        df['ì¶œì²˜'] = 'DOCX ë¬¸ì„œ'
        df['ìœ í˜•'] = df['ìš”êµ¬ì‚¬í•­ ID (RFP ì›ì²œ)'].apply(lambda x: 'ê¸°ëŠ¥' if x.startswith('FUN') else 'ë¹„ê¸°ëŠ¥')
        
        column_order = [
            'ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ID', 'ìš”êµ¬ì‚¬í•­ ê·¸ë£¹', 'ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ë‚´ìš©', 
            'ìš”êµ¬ì‚¬í•­ ID (RFP ì›ì²œ)', 'ìš”êµ¬ì‚¬í•­ ëª…ì¹­ (RFP ì›ì²œ)', 'ìœ í˜•', 'ì¶œì²˜'
        ]
        return df.reindex(columns=column_order)

# --- Streamlit UI êµ¬ì„± ---
def main():
    st.set_page_config(page_title="ìš”êµ¬ì‚¬í•­ ì¶”ì¶œê¸°", layout="wide", initial_sidebar_state="expanded")
    st.title("ğŸ“„ DOCX ìš”êµ¬ì‚¬í•­ ì •ì˜ì„œ ìë™ ì¶”ì¶œê¸°")
    st.markdown("MS Wordì˜ **ë“¤ì—¬ì“°ê¸°(Indentation)**ë¥¼ ë¶„ì„í•˜ì—¬, ê¸€ë¨¸ë¦¬ ê¸°í˜¸ ë° í‘œ(Table)ì— í¬í•¨ëœ ìš”êµ¬ì‚¬í•­ ëª©ë¡ì„ ì •í™•í•˜ê²Œ ìƒì„±í•©ë‹ˆë‹¤.")

    with st.sidebar:
        st.header("âš™ï¸ ë¶„ì„ ì„¤ì •")
        business_code = st.text_input("ì‚¬ì—… ì½”ë“œ", value="MFDS", help="ìš”êµ¬ì‚¬í•­ ID ìƒì„±ì— ì‚¬ìš©ë©ë‹ˆë‹¤.")
        st.info("ì´ì œ ë¸”ë¦¿ ë¬¸ìë¥¼ ì§ì ‘ ì…ë ¥í•  í•„ìš” ì—†ì´, ë¬¸ì„œì˜ **ê¸€ë¨¸ë¦¬ ê¸°í˜¸ ìŠ¤íƒ€ì¼**ê³¼ **ë“¤ì—¬ì“°ê¸°**ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìë™ìœ¼ë¡œ ê³„ì¸µì„ ë¶„ì„í•©ë‹ˆë‹¤.")

    uploaded_file = st.file_uploader("ë¶„ì„í•  .docx íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["docx"])

    if uploaded_file is not None:
        try:
            # ë¸”ë¦¿ ì„¤ì •ì€ ë” ì´ìƒ í•„ìš” ì—†ìœ¼ë¯€ë¡œ ë¹ˆ ë¬¸ìì—´ ì „ë‹¬
            level1_bullets = ""
            level2_bullets = ""
            
            extractor = StreamlitDocxExtractor(business_code=business_code)
            
            with st.spinner("íŒŒì¼ ë¶„ì„ ë° ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ ì¤‘... (ë“¤ì—¬ì“°ê¸° ë¶„ì„ ì¤‘)"):
                requirements_df = extractor.process(uploaded_file, level1_bullets, level2_bullets)

            if not requirements_df.empty:
                st.success(f"âœ… ì´ {len(requirements_df)}ê°œì˜ ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ì„ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
                st.dataframe(requirements_df)

                @st.cache_data
                def convert_df_to_csv(_df):
                    return _df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')

                csv_data = convert_df_to_csv(requirements_df)
                
                st.download_button(
                    label="ğŸ“¥ ì¶”ì¶œ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ",
                    data=csv_data,
                    file_name=f"extracted_requirements_{business_code}.csv",
                    mime="text/csv",
                )
            else:
                pass

        except Exception as e:
            st.error(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            st.exception(e)

if __name__ == '__main__':
    main()
