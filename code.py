# app.py

import streamlit as st
import re
import pandas as pd
from typing import List, Dict, Tuple
import docx
from docx.document import Document
from docx.table import Table
from docx.text.paragraph import Paragraph
import io

# --- ë¡œì§ í´ë˜ìŠ¤: í…ìŠ¤íŠ¸ ì¶”ì¶œì— ëª¨ë“  ì—­ëŸ‰ì„ ì§‘ì¤‘ ---
class AdvancedDocxExtractor:
    """
    LLM ì…ë ¥ì„ ìœ„í•œ ê°€ì¥ ì •í™•í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œì— ì§‘ì¤‘í•˜ëŠ” í´ë˜ìŠ¤.
    í…Œì´ë¸”, ë³µí•© ë¬¸ë‹¨, ë‹¤ì–‘í•œ ë¸”ë¦¿, ë“¤ì—¬ì“°ê¸°ë¥¼ ëª¨ë‘ ë¶„ì„í•˜ì—¬ ê³„ì¸µ êµ¬ì¡°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    def __init__(self, business_code: str = "MFDS"):
        self.business_code = business_code

    def _get_all_paragraphs_in_order(self, doc: Document) -> List[Paragraph]:
        """ë¬¸ì„œì˜ ëª¨ë“  ë¬¸ë‹¨ ê°ì²´ë¥¼ í‘œ ì•ˆì˜ ë‚´ìš©ê¹Œì§€ í¬í•¨í•˜ì—¬ ìˆœì„œëŒ€ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        all_paragraphs = []
        for block in doc.element.body:
            if isinstance(block, docx.oxml.text.paragraph.CT_P):
                all_paragraphs.append(Paragraph(block, doc))
            elif isinstance(block, docx.oxml.table.CT_Tbl):
                table = Table(block, doc)
                for row in table.rows:
                    for cell in row.cells:
                        # í…Œì´ë¸” ì…€ ë‚´ì˜ ë¬¸ë‹¨ë„ ëª¨ë‘ ì¶”ê°€
                        for p in cell.paragraphs:
                            if p.text.strip(): # ë‚´ìš©ì´ ìˆëŠ” ë¬¸ë‹¨ë§Œ ì¶”ê°€
                                all_paragraphs.append(p)
        return all_paragraphs

    def _get_indentation_level(self, p: Paragraph) -> float:
        """ë¬¸ë‹¨ì˜ ë“¤ì—¬ì“°ê¸° ìˆ˜ì¤€ì„ ë°˜í™˜í•©ë‹ˆë‹¤. (Noneì¼ ê²½ìš° 0ìœ¼ë¡œ ì²˜ë¦¬)"""
        indent = p.paragraph_format.left_indent
        return indent.pt if indent else 0.0

    # [í•µì‹¬ ë¡œì§] ê³„ì¸µ êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ì—¬ DataFrameìš© ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    def _parse_hierarchical_text(self, paragraphs: List[Paragraph], req_id: str, req_name: str) -> List[Dict]:
        extracted_items = []
        item_counter = 1
        # (ë“¤ì—¬ì“°ê¸° ìˆ˜ì¤€, í…ìŠ¤íŠ¸)ë¥¼ ì €ì¥í•˜ëŠ” ìŠ¤íƒ
        parent_stack: List[Tuple[float, str]] = []

        for p in paragraphs:
            # 1. ë¬¸ë‹¨ì„ ì¤„ ë‹¨ìœ„ë¡œ ë¶„í•´
            lines = [line for line in p.text.split('\n') if line.strip()]
            if not lines:
                continue

            # ë¬¸ë‹¨ ìì²´ì˜ ë“¤ì—¬ì“°ê¸° ìˆ˜ì¤€ì„ ëª¨ë“  ì¤„ì´ ìƒì†
            base_indent = self._get_indentation_level(p)

            for line in lines:
                # 2. ê° ì¤„ì˜ ë¸”ë¦¿ê³¼ í…ìŠ¤íŠ¸ ë¶„ë¦¬
                # ë‹¤ì–‘í•œ ë¸”ë¦¿ ë¬¸ì(ìˆ«ì í¬í•¨)ì™€ ê³µë°±ì„ ì²˜ë¦¬í•˜ëŠ” ì •ê·œì‹
                match = re.match(r'^\s*([*â—¦â—‹â€¢Â·â–´-]|[ê°€-í£]\.|[0-9]+\.)\s*(.*)', line)
                if match:
                    bullet = match.group(1)
                    content = match.group(2).strip()
                    # ë¸”ë¦¿ì´ ìˆëŠ” ê²½ìš°, ë“¤ì—¬ì“°ê¸° ìˆ˜ì¤€ì„ ì•½ê°„ ë†’ì—¬ ê³„ì¸µì„ ëª…í™•íˆ í•¨
                    current_indent = base_indent + 5 
                else:
                    bullet = ""
                    content = line.strip()
                    current_indent = base_indent

                if not content:
                    continue

                # 3. ë¶€ëª¨ í•­ëª© ê²°ì •
                # ìŠ¤íƒì„ í™•ì¸í•˜ì—¬ í˜„ì¬ í•­ëª©ë³´ë‹¤ ë“¤ì—¬ì“°ê¸°ê°€ ê¹Šê±°ë‚˜ ê°™ì€ ë¶€ëª¨ë¥¼ ëª¨ë‘ ì œê±°
                while parent_stack and current_indent <= parent_stack[-1][0]:
                    parent_stack.pop()
                
                parent_text = parent_stack[-1][1] if parent_stack else req_name
                
                # 4. ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                extracted_items.append({
                    'ìƒìœ„ ìš”êµ¬ì‚¬í•­ ID': req_id,
                    'ìƒìœ„ ìš”êµ¬ì‚¬í•­ ëª…ì¹­': req_name,
                    'ID': f"{req_id}-{item_counter:03d}",
                    'ë ˆë²¨': len(parent_stack) + 1,
                    'êµ¬ë¶„(ë¸”ë¦¿)': bullet,
                    'ë‚´ìš©': content,
                    'ìƒìœ„ í•­ëª©': parent_text,
                })
                item_counter += 1

                # í˜„ì¬ í•­ëª©ì„ ë‹¤ìŒ í•­ëª©ì˜ ì ì¬ì  ë¶€ëª¨ë¡œ ìŠ¤íƒì— ì¶”ê°€
                parent_stack.append((current_indent, content))

        return extracted_items


    def process(self, docx_file: io.BytesIO) -> pd.DataFrame:
        doc = docx.Document(docx_file)
        all_paragraphs = self._get_all_paragraphs_in_order(doc)
        
        all_requirements = []
        
        # 'ìš”êµ¬ì‚¬í•­ ëª…ì¹­' ë˜ëŠ” 'ìš”êµ¬ì‚¬í•­ ê³ ìœ ë²ˆí˜¸'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¸”ë¡ì„ ì‹ë³„
        block_starts = [i for i, p in enumerate(all_paragraphs) if 'ìš”êµ¬ì‚¬í•­ ëª…ì¹­' in p.text or 'ìš”êµ¬ì‚¬í•­ ê³ ìœ ë²ˆí˜¸' in p.text]
        if not block_starts:
            st.warning("ë¬¸ì„œì—ì„œ 'ìš”êµ¬ì‚¬í•­ ëª…ì¹­' ë˜ëŠ” 'ìš”êµ¬ì‚¬í•­ ê³ ìœ ë²ˆí˜¸' í‚¤ì›Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
            
        st.info(f"ì´ {len(block_starts)}ê°œì˜ ìš”êµ¬ì‚¬í•­ ë¸”ë¡ ì‹œì‘ì ì„ ì‹ë³„í–ˆìŠµë‹ˆë‹¤.")

        for i, start_idx in enumerate(block_starts):
            end_idx = block_starts[i+1] if i + 1 < len(block_starts) else len(all_paragraphs)
            
            block_paragraphs = all_paragraphs[start_idx:end_idx]
            block_text = "\n".join([p.text for p in block_paragraphs])
            
            # IDì™€ ëª…ì¹­ ì¶”ì¶œ (ë” ìœ ì—°í•˜ê²Œ)
            req_id_match = re.search(r'ìš”êµ¬ì‚¬í•­\s*ê³ ìœ ë²ˆí˜¸\s*[:]?\s*([A-Z0-9-]{3,})', block_text, re.IGNORECASE)
            req_name_match = re.search(r'ìš”êµ¬ì‚¬í•­\s*ëª…ì¹­\s*[:]?\s*(.+?)(?:\n|$)', block_text)
            
            req_id = req_id_match.group(1).strip() if req_id_match else f"REQ-TEMP-{i+1:03d}"
            req_name = req_name_match.group(1).strip() if req_name_match else "ëª…ì¹­ ë¯¸ìƒ"

            # 'ì„¸ë¶€ë‚´ìš©' í‚¤ì›Œë“œë¥¼ ì°¾ì•„ ê·¸ ì´í›„ì˜ ë¬¸ë‹¨ë§Œ íŒŒì‹± ëŒ€ìƒìœ¼ë¡œ í•¨
            details_start_offset = -1
            for j, p in enumerate(block_paragraphs):
                if 'ì„¸ë¶€ë‚´ìš©' in p.text:
                    details_start_offset = j + 1
                    break
            
            if details_start_offset != -1:
                details_paragraphs = block_paragraphs[details_start_offset:]
                parsed_items = self._parse_hierarchical_text(details_paragraphs, req_id, req_name)
                all_requirements.extend(parsed_items)

        if not all_requirements:
            st.warning("ìš”êµ¬ì‚¬í•­ ë¸”ë¡ì€ ì°¾ì•˜ìœ¼ë‚˜, ì„¸ë¶€ ë‚´ìš©ì„ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë¬¸ì„œ êµ¬ì¡°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return pd.DataFrame()

        df = pd.DataFrame(all_requirements)
        
        # LLMì´ ì´í•´í•˜ê¸° ì¢‹ì€ ìˆœì„œë¡œ ì»¬ëŸ¼ ì •ë¦¬
        column_order = [
            'ID', 'ë ˆë²¨', 'ë‚´ìš©', 'ìƒìœ„ í•­ëª©', 'êµ¬ë¶„(ë¸”ë¦¿)', 
            'ìƒìœ„ ìš”êµ¬ì‚¬í•­ ID', 'ìƒìœ„ ìš”êµ¬ì‚¬í•­ ëª…ì¹­'
        ]
        return df.reindex(columns=[col for col in column_order if col in df.columns])

# --- Streamlit UI êµ¬ì„± ---
def main():
    st.set_page_config(page_title="LLMìš© ìš”êµ¬ì‚¬í•­ í…ìŠ¤íŠ¸ ì¶”ì¶œê¸°", layout="wide")
    st.title("ğŸ“‘ DOCX ìš”êµ¬ì‚¬í•­ í…ìŠ¤íŠ¸ ì¶”ì¶œê¸° (For LLM)")
    st.markdown("LLM ì…ë ¥ì„ ìœ„í•´, **í…Œì´ë¸”, ë“¤ì—¬ì“°ê¸°, ë¸”ë¦¿**ì„ ì¢…í•© ë¶„ì„í•˜ì—¬ ë¬¸ì„œì˜ ê³„ì¸µ êµ¬ì¡°ë¥¼ í¬í•¨í•œ í…ìŠ¤íŠ¸ë¥¼ ì •í™•í•˜ê²Œ ì¶”ì¶œí•©ë‹ˆë‹¤.")

    with st.sidebar:
        st.header("âš™ï¸ ë¶„ì„ ì„¤ì •")
        business_code = st.text_input("ì‚¬ì—… ì½”ë“œ (ID ìƒì„±ìš©)", value="MFDS")
        st.info("ì´ ë„êµ¬ëŠ” ë¸”ë¦¿ ë¬¸ì ì„¤ì • ì—†ì´, ë¬¸ì„œì˜ êµ¬ì¡° ìì²´ë¥¼ ë¶„ì„í•˜ì—¬ ìë™ìœ¼ë¡œ ê³„ì¸µì„ ì¸ì‹í•©ë‹ˆë‹¤.")

    uploaded_file = st.file_uploader("ë¶„ì„í•  .docx íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["docx"])

    if uploaded_file is not None:
        try:
            extractor = AdvancedDocxExtractor(business_code=business_code)
            
            with st.spinner("ë¬¸ì„œ êµ¬ì¡° ë¶„ì„ ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘..."):
                file_bytes = io.BytesIO(uploaded_file.getvalue())
                extracted_df = extractor.process(file_bytes)

            if not extracted_df.empty:
                st.success(f"âœ… ì´ {len(extracted_df)}ê°œì˜ ìš”êµ¬ì‚¬í•­ í•­ëª©ì„ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
                st.info("ì•„ë˜ëŠ” LLMì´ ì²˜ë¦¬í•˜ê¸° ì¢‹ë„ë¡ ê³„ì¸µ êµ¬ì¡°(ë ˆë²¨, ìƒìœ„ í•­ëª©)ë¥¼ í¬í•¨í•œ ê²°ê³¼ì…ë‹ˆë‹¤.")
                st.dataframe(extracted_df)

                @st.cache_data
                def convert_df_to_csv(_df):
                    return _df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')

                csv_data = convert_df_to_csv(extracted_df)
                
                st.download_button(
                    label="ğŸ“¥ ì¶”ì¶œ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ",
                    data=csv_data,
                    file_name=f"extracted_requirements_for_llm_{business_code}.csv",
                    mime="text/csv",
                )
            else:
                # extractor.process ë‚´ë¶€ì—ì„œ st.warningì´ í˜¸ì¶œë¨
                pass

        except Exception as e:
            st.error(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            st.exception(e)

if __name__ == '__main__':
    main()
