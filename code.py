# app.py

import streamlit as st
import re
import pandas as pd
from typing import List, Dict
import docx
from docx.document import Document
from docx.table import Table
import io

# --- ë¡œì§ í´ë˜ìŠ¤ ---
class StreamlitDocxExtractor:
    """
    Streamlit í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •ëœ DOCX ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ í´ë˜ìŠ¤.
    ì‚¬ìš©ìê°€ ë¸”ë¦¿ ì²´ê³„ë¥¼ ì§ì ‘ ì„ íƒí•˜ì—¬ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    def __init__(self, business_code: str = "MFDS"):
        self.business_code = business_code

    def _generate_id(self, req_id: str, sequence: int) -> str:
        """ìš”êµ¬ì‚¬í•­ IDë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        req_type_code = "F" if req_id.startswith("FUN") else "Q"
        id_num_match = re.search(r'\d+', req_id)
        id_num = id_num_match.group(0) if id_num_match else "000"
        return f"REQ-{self.business_code}-{req_type_code}-{id_num}{sequence:03d}"

    def get_all_text_from_doc(self, doc: Document) -> str:
        """ë¬¸ì„œì˜ ëª¨ë“  ìš”ì†Œë¥¼ ì¬ê·€ì ìœ¼ë¡œ íƒìƒ‰í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ì¬êµ¬ì„±í•©ë‹ˆë‹¤."""
        full_text = []
        for block in doc.element.body:
            if hasattr(block, 'text'): # Paragraph
                full_text.append(block.text)
            elif isinstance(block, docx.oxml.table.CT_Tbl): # Table
                table = docx.table.Table(block, doc)
                for row in table.rows:
                    row_texts = [self.get_all_text_from_cell(cell) for cell in row.cells]
                    full_text.append("\t".join(row_texts)) # ì…€ ê°„ì€ íƒ­ìœ¼ë¡œ êµ¬ë¶„
        return "\n".join(full_text)

    def get_all_text_from_cell(self, cell: docx.table._Cell) -> str:
        """í‘œì˜ ì…€(cell) ì•ˆì— ìˆëŠ” ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤ (ì¤‘ì²© í‘œ í¬í•¨)."""
        cell_text = []
        for block in cell._element.body:
            if hasattr(block, 'text'):
                cell_text.append(block.text)
            elif isinstance(block, docx.oxml.table.CT_Tbl):
                inner_table = docx.table.Table(block, cell)
                for row in inner_table.rows:
                    row_texts = [self.get_all_text_from_cell(inner_cell) for inner_cell in row.cells]
                    cell_text.append("\t".join(row_texts))
        return "\n".join(cell_text)

    def _parse_block_content(self, req_id: str, req_name: str, content: str, level1_bullets: str, level2_bullets: str) -> List[Dict]:
        """
        ì‚¬ìš©ìê°€ ì§€ì •í•œ ë¸”ë¦¿ì„ ê¸°ë°˜ìœ¼ë¡œ ì„¸ë¶€ë‚´ìš© í…ìŠ¤íŠ¸ë¥¼ ê³„ì¸µì ìœ¼ë¡œ íŒŒì‹±í•©ë‹ˆë‹¤.
        """
        final_requirements = []
        bfn_seq_counter = 1

        l1_escaped = re.escape(level1_bullets)
        l2_escaped = re.escape(level2_bullets)
        
        sfr_groups_text = re.split(f'\n\s*(?=[{l1_escaped}])', content)

        for group_text in sfr_groups_text:
            group_text = group_text.strip()
            if not group_text: continue

            lines = [line.strip() for line in group_text.split('\n') if line.strip()]
            if not lines: continue

            group_title = re.sub(f'^[{l1_escaped}]+\s*', '', lines[0])

            detailed_points = []
            for line in lines:
                if re.match(f'^\s*[{l2_escaped}]', line):
                    detailed_points.append(re.sub(f'^\s*[{l2_escaped}]+\s*', '', line))

            if not detailed_points:
                final_requirements.append({
                    'ìš”êµ¬ì‚¬í•­ ê·¸ë£¹': group_title, 'ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ë‚´ìš©': group_title,
                    'ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ID': self._generate_id(req_id, bfn_seq_counter)
                })
                bfn_seq_counter += 1
            else:
                for point in detailed_points:
                    final_requirements.append({
                        'ìš”êµ¬ì‚¬í•­ ê·¸ë£¹': group_title, 'ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ë‚´ìš©': point,
                        'ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ID': self._generate_id(req_id, bfn_seq_counter)
                    })
                    bfn_seq_counter += 1
        return final_requirements

    def process(self, docx_file: io.BytesIO, level1_bullets: str, level2_bullets: str) -> pd.DataFrame:
        """
        ì—…ë¡œë“œëœ DOCX íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ ìš”êµ¬ì‚¬í•­ì„ DataFrameìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        doc = docx.Document(docx_file)

        st.info("ë¬¸ì„œì˜ í…ìŠ¤íŠ¸ë¥¼ ì¬êµ¬ì„±í•˜ëŠ” ì¤‘...")
        full_text = self.get_all_text_from_doc(doc)
        
        block_pattern = r"(ìš”êµ¬ì‚¬í•­ ë¶„ë¥˜(?:.|\n)*?ìš”êµ¬ì‚¬í•­ ê³ ìœ ë²ˆí˜¸\s+[A-Z]{3}-\d{3}(?:.|\n)*?)(?=ìš”êµ¬ì‚¬í•­ ë¶„ë¥˜|$)"
        blocks = re.findall(block_pattern, full_text)

        st.info(f"ì´ {len(blocks)}ê°œì˜ ìš”êµ¬ì‚¬í•­ ë¸”ë¡ì„ ì‹ë³„í–ˆìŠµë‹ˆë‹¤.")
        if not blocks:
            st.warning("ë¬¸ì„œì—ì„œ 'ìš”êµ¬ì‚¬í•­ ë¶„ë¥˜/ê³ ìœ ë²ˆí˜¸' íŒ¨í„´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¬¸ì„œ êµ¬ì¡°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return pd.DataFrame()

        all_requirements = []
        for block in blocks:
            req_id_match = re.search(r'ìš”êµ¬ì‚¬í•­ ê³ ìœ ë²ˆí˜¸\s+([A-Z]{3}-\d{3})', block)
            req_name_match = re.search(r'ìš”êµ¬ì‚¬í•­ ëª…ì¹­\s+(.+?)(?:\n|$)', block)

            if not req_id_match or not req_name_match: continue
            
            req_id, req_name = req_id_match.group(1).strip(), req_name_match.group(1).strip()
            details_match = re.search(r'ì„¸ë¶€ë‚´ìš©\s*((?:.|\n)*)', block, re.DOTALL)
            
            if details_match:
                content = details_match.group(1).strip()
                parsed_reqs = self._parse_block_content(req_id, req_name, content, level1_bullets, level2_bullets)
                for req in parsed_reqs:
                    req['ìš”êµ¬ì‚¬í•­ ID (RFP ì›ì²œ)'] = req_id
                    req['ìš”êµ¬ì‚¬í•­ ëª…ì¹­ (RFP ì›ì²œ)'] = req_name
                all_requirements.extend(parsed_reqs)

        if not all_requirements:
            st.warning("ìš”êµ¬ì‚¬í•­ ë¸”ë¡ì€ ì°¾ì•˜ìœ¼ë‚˜, ì„¸ë¶€ ë‚´ìš©ì„ íŒŒì‹±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë¸”ë¦¿ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return pd.DataFrame()

        df = pd.DataFrame(all_requirements)
        df['ì¶œì²˜'] = 'DOCX ë¬¸ì„œ'
        df['ìœ í˜•'] = df['ìš”êµ¬ì‚¬í•­ ID (RFP ì›ì²œ)'].apply(lambda x: 'ê¸°ëŠ¥' if x.startswith('FUN') else 'ë¹„ê¸°ëŠ¥')
        
        column_order = [
            'ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ID', 'ìš”êµ¬ì‚¬í•­ ê·¸ë£¹', 'ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ë‚´ìš©', 
            'ìš”êµ¬ì‚¬í•­ ID (RFP ì›ì²œ)', 'ìš”êµ¬ì‚¬í•­ ëª…ì¹­ (RFP ì›ì²œ)', 'ìœ í˜•', 'ì¶œì²˜'
        ]
        return df[column_order]

# --- Streamlit UI êµ¬ì„± ---
def main():
    st.set_page_config(page_title="ìš”êµ¬ì‚¬í•­ ì¶”ì¶œê¸°", layout="wide", initial_sidebar_state="expanded")
    st.title("ğŸ“„ DOCX ìš”êµ¬ì‚¬í•­ ì •ì˜ì„œ ìë™ ì¶”ì¶œê¸°")
    st.markdown("DOCX í˜•ì‹ì˜ ìš”êµ¬ì‚¬í•­ ì •ì˜ì„œë¥¼ ì—…ë¡œë“œí•˜ë©´, ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ëª©ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤.")

    with st.sidebar:
        st.header("âš™ï¸ ë¶„ì„ ì„¤ì •")
        
        business_code = st.text_input("ì‚¬ì—… ì½”ë“œ", value="MFDS", help="ìš”êµ¬ì‚¬í•­ ID ìƒì„±ì— ì‚¬ìš©ë©ë‹ˆë‹¤.")
        
        st.markdown("---")
        
        st.subheader("ë¸”ë¦¿(Bullet) ì²´ê³„ ì„¤ì •")
        level1_bullets = st.text_input("1ì°¨ ë¸”ë¦¿ ë¬¸ì (ê·¸ë£¹)", value="â—¦â—‹â€¢", help="ìš”êµ¬ì‚¬í•­ ê·¸ë£¹ ê¸°í˜¸ë¥¼ ëª¨ë‘ ì…ë ¥í•˜ì„¸ìš”.")
        level2_bullets = st.text_input("2ì°¨ ë¸”ë¦¿ ë¬¸ì (ì„¸ë¶€ í•­ëª©)", value="-*Â·â–´", help="ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ê¸°í˜¸ë¥¼ ëª¨ë‘ ì…ë ¥í•˜ì„¸ìš”.")
        st.info("ë¬¸ì„œì— ì‚¬ìš©ëœ ë¸”ë¦¿ì„ ì •í™•í•˜ê²Œ ì…ë ¥í•´ì•¼ ë¶„ì„ ì„±ê³µë¥ ì´ ë†’ì•„ì§‘ë‹ˆë‹¤.")

    uploaded_file = st.file_uploader("ë¶„ì„í•  .docx íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["docx"])

    if uploaded_file is not None:
        try:
            extractor = StreamlitDocxExtractor(business_code=business_code)
            
            with st.spinner("íŒŒì¼ ë¶„ì„ ë° ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ ì¤‘..."):
                requirements_df = extractor.process(uploaded_file, level1_bullets, level2_bullets)

            if not requirements_df.empty:
                st.success(f"âœ… ì´ {len(requirements_df)}ê°œì˜ ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ì„ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
                st.dataframe(requirements_df)

                @st.cache_data
                def convert_df_to_csv(df):
                    return df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')

                csv_data = convert_df_to_csv(requirements_df)
                
                st.download_button(
                    label="ğŸ“¥ ì¶”ì¶œ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ",
                    data=csv_data,
                    file_name=f"extracted_requirements_{business_code}.csv",
                    mime="text/csv",
                )
            else:
                st.warning("ë¶„ì„ì€ ì™„ë£Œë˜ì—ˆì§€ë§Œ ì¶”ì¶œëœ ìš”êµ¬ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤. ë¬¸ì„œ ë‚´ìš©ì´ë‚˜ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

        except Exception as e:
            st.error(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            st.exception(e) # ê°œë°œì í™•ì¸ìš© ìƒì„¸ ì—ëŸ¬ ë¡œê·¸

if __name__ == '__main__':
    main()