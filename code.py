# app.py

import streamlit as st
import re
import pandas as pd
from typing import List, Dict, Union
import docx
from docx.document import Document
from docx.table import Table, _Cell
from docx.text.paragraph import Paragraph
import io

# --- ë¡œì§ í´ë˜ìŠ¤ ---
class StreamlitDocxExtractor:
    """
    [ìµœì¢… ì™„ì„±ë³¸] ì¼ë°˜ ë¬¸ë‹¨ê³¼ í‘œ(Table)ì— í¬í•¨ëœ ìš”êµ¬ì‚¬í•­ì„ ëª¨ë‘ ë¶„ì„í•˜ëŠ” í´ë˜ìŠ¤.
    ìŠ¤íƒ€ì¼ ë¶„ì„ê³¼ ì „ì²´ ìš”ì†Œ ìˆœíšŒë¥¼ ê²°í•©í•˜ì—¬ ê°€ì¥ ê²¬ê³ í•˜ê²Œ ì‘ë™í•©ë‹ˆë‹¤.
    """
    def __init__(self, business_code: str = "MFDS"):
        self.business_code = business_code

    def _generate_id(self, req_id: str, sequence: int) -> str:
        """ìš”êµ¬ì‚¬í•­ IDë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        req_type_code = "F" if req_id.startswith("FUN") else "Q"
        id_num_match = re.search(r'\d+', req_id)
        id_num = id_num_match.group(0) if id_num_match else "000"
        return f"REQ-{self.business_code}-{req_type_code}-{id_num}{sequence:03d}"

    def _get_all_paragraphs_in_order(self, doc: Document) -> List[Paragraph]:
        """
        [í•µì‹¬] ë¬¸ì„œì˜ ëª¨ë“  ë¬¸ë‹¨ ê°ì²´ë¥¼ í‘œ ì•ˆì˜ ë‚´ìš©ê¹Œì§€ í¬í•¨í•˜ì—¬ ìˆœì„œëŒ€ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.
        """
        all_paragraphs = []
        # doc.element.bodyë¥¼ ì§ì ‘ ìˆœíšŒí•˜ì—¬ ë¬¸ë‹¨ê³¼ í‘œë¥¼ ìˆœì„œëŒ€ë¡œ ê°€ì ¸ì˜´
        for block in doc.element.body:
            if isinstance(block, docx.oxml.text.paragraph.CT_P):
                all_paragraphs.append(Paragraph(block, doc))
            elif isinstance(block, docx.oxml.table.CT_Tbl):
                table = Table(block, doc)
                for row in table.rows:
                    for cell in row.cells:
                        # ì…€ ì•ˆì˜ ë¬¸ë‹¨ë“¤ì„ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                        for para in cell.paragraphs:
                            all_paragraphs.append(para)
        return all_paragraphs

    def _is_bullet_paragraph(self, p: Paragraph, bullet_chars: str) -> bool:
        """
        ë¬¸ë‹¨ì´ ì£¼ì–´ì§„ ë¸”ë¦¿ ë¬¸ìë¡œ ì‹œì‘í•˜ê±°ë‚˜, ìë™ ê¸€ë¨¸ë¦¬ ê¸°í˜¸ ìŠ¤íƒ€ì¼ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤.
        """
        line_text = p.text.strip()
        if not line_text:
            return False
            
        # 1. 'List Paragraph' ìŠ¤íƒ€ì¼ì¸ì§€ í™•ì¸ (ê°€ì¥ í™•ì‹¤í•œ ë°©ë²•)
        if p.style and 'List' in p.style.name:
            return True
        # 2. í…ìŠ¤íŠ¸ê°€ ì§ì ‘ ì…ë ¥ëœ ë¸”ë¦¿ ë¬¸ìë¡œ ì‹œì‘í•˜ëŠ”ì§€ í™•ì¸
        if re.match(f'^[{re.escape(bullet_chars)}]', line_text):
            return True
        return False
    
    def _parse_details_from_paragraphs(self, paragraphs: List[Paragraph], req_id: str, level1_bullets: str, level2_bullets: str) -> List[Dict]:
        """
        ì£¼ì–´ì§„ ë¬¸ë‹¨ ë¦¬ìŠ¤íŠ¸ë¥¼ ìˆœíšŒí•˜ë©° ê³„ì¸µì  ìš”êµ¬ì‚¬í•­ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
        """
        final_requirements = []
        bfn_seq_counter = 1
        current_group_title = ""
        
        for i, p in enumerate(paragraphs):
            line = p.text.strip()
            if not line:
                continue

            # 1ì°¨ ë¸”ë¦¿ì¸ì§€ í™•ì¸
            is_level1 = self._is_bullet_paragraph(p, level1_bullets)
            is_level2 = self._is_bullet_paragraph(p, level2_bullets)

            # 1ì°¨ ë¸”ë¦¿ì´ë©´ì„œ 2ì°¨ ë¸”ë¦¿ì´ ì•„ë‹Œ ê²½ìš°
            if is_level1 and not (is_level2 and current_group_title):
                current_group_title = re.sub(f'^[{re.escape(level1_bullets)}]+\s*', '', line)
                
                # ë‹¤ìŒ ë¬¸ë‹¨ì´ 2ì°¨ ë¸”ë¦¿ì¸ì§€ ë¯¸ë¦¬ í™•ì¸
                is_next_l2 = False
                if i + 1 < len(paragraphs):
                    next_p = paragraphs[i+1]
                    if self._is_bullet_paragraph(next_p, level2_bullets):
                        is_next_l2 = True
                
                # 2ì°¨ ë¸”ë¦¿ì´ ì—†ëŠ” ë‹¨ë… 1ì°¨ ë¸”ë¦¿ì´ë©´, ê·¸ ìì²´ê°€ ìš”êµ¬ì‚¬í•­
                if not is_next_l2:
                    final_requirements.append({
                        'ìš”êµ¬ì‚¬í•­ ê·¸ë£¹': current_group_title, 'ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ë‚´ìš©': current_group_title,
                        'ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ID': self._generate_id(req_id, bfn_seq_counter)
                    })
                    bfn_seq_counter += 1
            
            # 2ì°¨ ë¸”ë¦¿ì´ê³  í˜„ì¬ ê·¸ë£¹ì— ì†í•´ìˆëŠ” ê²½ìš°
            elif is_level2 and current_group_title:
                point_text = re.sub(f'^\s*[{re.escape(level2_bullets)}]+\s*', '', line)
                final_requirements.append({
                    'ìš”êµ¬ì‚¬í•­ ê·¸ë£¹': current_group_title, 'ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ë‚´ìš©': point_text,
                    'ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ID': self._generate_id(req_id, bfn_seq_counter)
                })
                bfn_seq_counter += 1

        return final_requirements

    def process(self, docx_file: io.BytesIO, level1_bullets: str, level2_bullets: str) -> pd.DataFrame:
        """
        ë¬¸ì„œ ì „ì²´ë¥¼ ìˆœíšŒí•˜ë©° í‘œ ë‚´ë¶€ë¥¼ í¬í•¨í•œ ëª¨ë“  ìš”êµ¬ì‚¬í•­ì„ ë¶„ì„í•©ë‹ˆë‹¤.
        """
        doc = docx.Document(docx_file)
        
        # 1. ë¬¸ì„œì˜ ëª¨ë“  ë¬¸ë‹¨ ê°ì²´ë¥¼ ìˆœì„œëŒ€ë¡œ ê°€ì ¸ì˜¤ê¸° (í‘œ í¬í•¨)
        all_paragraphs = self._get_all_paragraphs_in_order(doc)
        
        # 2. 'ìš”êµ¬ì‚¬í•­ ë¶„ë¥˜' í‚¤ì›Œë“œë¡œ ë¸”ë¡ì˜ ì‹œì‘/ë ì¸ë±ìŠ¤ ì°¾ê¸°
        block_markers = []
        for i, p in enumerate(all_paragraphs):
            if 'ìš”êµ¬ì‚¬í•­ ë¶„ë¥˜' in p.text:
                block_markers.append(i)
        
        st.info(f"ì´ {len(block_markers)}ê°œì˜ ìš”êµ¬ì‚¬í•­ ë¸”ë¡ ì‹œì‘ì ì„ ì‹ë³„í–ˆìŠµë‹ˆë‹¤.")
        if not block_markers:
            st.warning("ë¬¸ì„œì—ì„œ 'ìš”êµ¬ì‚¬í•­ ë¶„ë¥˜' í‚¤ì›Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¬¸ì„œ êµ¬ì¡°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return pd.DataFrame()

        all_requirements = []
        for i, start_index in enumerate(block_markers):
            end_index = block_markers[i+1] if i + 1 < len(block_markers) else len(all_paragraphs)
            
            # í˜„ì¬ ë¸”ë¡ì— í•´ë‹¹í•˜ëŠ” ë¬¸ë‹¨ ê°ì²´ë“¤
            block_paragraphs = all_paragraphs[start_index:end_index]
            block_text = "\n".join([p.text for p in block_paragraphs])
            
            # IDì™€ ëª…ì¹­ ì¶”ì¶œ
            req_id_match = re.search(r'ìš”êµ¬ì‚¬í•­ ê³ ìœ ë²ˆí˜¸\s+([A-Z]{3}-\d{3})', block_text)
            req_name_match = re.search(r'ìš”êµ¬ì‚¬í•­ ëª…ì¹­\s+(.+?)(?:\n|$)', block_text)

            if not req_id_match or not req_name_match: continue

            req_id, req_name = req_id_match.group(1).strip(), req_name_match.group(1).strip()
            
            # 'ì„¸ë¶€ë‚´ìš©' í‚¤ì›Œë“œ ì°¾ê¸°
            details_start_index_offset = -1
            for j, p in enumerate(block_paragraphs):
                if 'ì„¸ë¶€ë‚´ìš©' in p.text:
                    details_start_index_offset = j + 1
                    break
            
            if details_start_index_offset != -1:
                # 'ì„¸ë¶€ë‚´ìš©' ì´í›„ì˜ ë¬¸ë‹¨ë“¤ë§Œ íŒŒì‹± í•¨ìˆ˜ì— ì „ë‹¬
                details_paragraphs = block_paragraphs[details_start_index_offset:]
                parsed_reqs = self._parse_details_from_paragraphs(details_paragraphs, req_id, level1_bullets, level2_bullets)
                
                for req in parsed_reqs:
                    req['ìš”êµ¬ì‚¬í•­ ID (RFP ì›ì²œ)'] = req_id
                    req['ìš”êµ¬ì‚¬í•­ ëª…ì¹­ (RFP ì›ì²œ)'] = req_name
                all_requirements.extend(parsed_reqs)

        if not all_requirements:
            st.warning("ìš”êµ¬ì‚¬í•­ ë¸”ë¡ì€ ì°¾ì•˜ìœ¼ë‚˜, ì„¸ë¶€ ë‚´ìš©ì„ íŒŒì‹±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë¬¸ì„œ êµ¬ì¡°ë‚˜ ë¸”ë¦¿ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return pd.DataFrame()

        df = pd.DataFrame(all_requirements)
        df['ì¶œì²˜'] = 'DOCX ë¬¸ì„œ'
        df['ìœ í˜•'] = df['ìš”êµ¬ì‚¬í•­ ID (RFP ì›ì²œ)'].apply(lambda x: 'ê¸°ëŠ¥' if x.startswith('FUN') else 'ë¹„ê¸°ëŠ¥')
        
        column_order = [
            'ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ID', 'ìš”êµ¬ì‚¬í•­ ê·¸ë£¹', 'ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ë‚´ìš©', 
            'ìš”êµ¬ì‚¬í•­ ID (RFP ì›ì²œ)', 'ìš”êµ¬ì‚¬í•­ ëª…ì¹­ (RFP ì›ì²œ)', 'ìœ í˜•', 'ì¶œì²˜'
        ]
        return df.reindex(columns=column_order)

# --- Streamlit UI êµ¬ì„± ---
def main():
    st.set_page_config(page_title="ìš”êµ¬ì‚¬í•­ ì¶”ì¶œê¸°", layout="wide", initial_sidebar_state="expanded")
    st.title("ğŸ“„ DOCX ìš”êµ¬ì‚¬í•­ ì •ì˜ì„œ ìë™ ì¶”ì¶œê¸°")
    st.markdown("MS Wordì˜ ìë™ ê¸€ë¨¸ë¦¬ ê¸°í˜¸ ë° **í‘œ(Table)ì— í¬í•¨ëœ ë‚´ìš©**ê¹Œì§€ ë¶„ì„í•˜ì—¬ ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ëª©ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤.")

    with st.sidebar:
        st.header("âš™ï¸ ë¶„ì„ ì„¤ì •")
        
        business_code = st.text_input("ì‚¬ì—… ì½”ë“œ", value="MFDS", help="ìš”êµ¬ì‚¬í•­ ID ìƒì„±ì— ì‚¬ìš©ë©ë‹ˆë‹¤. (ì˜ˆ: REQ-**MFDS**-F-001001)")
        
        st.markdown("---")
        
        st.subheader("ë¸”ë¦¿(Bullet) ì²´ê³„ ì„¤ì •")
        level1_bullets = st.text_input("1ì°¨ ë¸”ë¦¿ ë¬¸ì (ê·¸ë£¹)", value="â—¦â—‹â€¢", help="ìš”êµ¬ì‚¬í•­ ê·¸ë£¹ì„ ë‚˜íƒ€ë‚´ëŠ” ê¸€ë¨¸ë¦¬ ê¸°í˜¸ë¥¼ ëª¨ë‘ ì…ë ¥í•˜ì„¸ìš”.")
        level2_bullets = st.text_input("2ì°¨ ë¸”ë¦¿ ë¬¸ì (ì„¸ë¶€ í•­ëª©)", value="-*Â·â–´", help="ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ì„ ë‚˜íƒ€ë‚´ëŠ” ê¸€ë¨¸ë¦¬ ê¸°í˜¸ë¥¼ ëª¨ë‘ ì…ë ¥í•˜ì„¸ìš”.")
        st.info("ë¬¸ì„œì— ì‚¬ìš©ëœ ë¸”ë¦¿ì„ ì •í™•íˆ ì…ë ¥í•´ì•¼ ë¶„ì„ ì„±ê³µë¥ ì´ ë†’ì•„ì§‘ë‹ˆë‹¤.")

    uploaded_file = st.file_uploader("ë¶„ì„í•  .docx íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["docx"])

    if uploaded_file is not None:
        try:
            extractor = StreamlitDocxExtractor(business_code=business_code)
            
            with st.spinner("íŒŒì¼ ë¶„ì„ ë° ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ ì¤‘... (í‘œ í¬í•¨)"):
                requirements_df = extractor.process(uploaded_file, level1_bullets, level2_bullets)

            if not requirements_df.empty:
                st.success(f"âœ… ì´ {len(requirements_df)}ê°œì˜ ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ì„ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
                st.dataframe(requirements_df)

                @st.cache_data
                def convert_df_to_csv(_df):
                    return _df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')

                csv_data = convert_df_to_csv(requirements_df)
                
                st.download_button(
                    label="ğŸ“¥ ì¶”ì¶œ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ",
                    data=csv_data,
                    file_name=f"extracted_requirements_{business_code}.csv",
                    mime="text/csv",
                )
            else:
                pass # ê²½ê³  ë©”ì‹œì§€ëŠ” process() í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì´ë¯¸ ì²˜ë¦¬ë¨

        except Exception as e:
            st.error(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            st.exception(e) # ê°œë°œì í™•ì¸ìš© ìƒì„¸ ì—ëŸ¬ ë¡œê·¸

if __name__ == '__main__':
    main()
