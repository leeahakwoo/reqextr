# app.py

import streamlit as st
import re
import pandas as pd
from typing import List, Dict, Tuple
import docx
from docx.document import Document
from docx.table import Table
from docx.text.paragraph import Paragraph
import io
import google.generativeai as genai

# --- 1ë‹¨ê³„ ë¡œì§: í…ìŠ¤íŠ¸ ì¶”ì¶œê¸° (ì´ì „ê³¼ ë™ì¼) ---
class AdvancedDocxExtractor:
    def __init__(self, business_code: str = "MFDS"):
        self.business_code = business_code

    def _get_all_paragraphs_in_order(self, doc: Document) -> List[Paragraph]:
        all_paragraphs = []
        for block in doc.element.body:
            if isinstance(block, docx.oxml.text.paragraph.CT_P):
                all_paragraphs.append(Paragraph(block, doc))
            elif isinstance(block, docx.oxml.table.CT_Tbl):
                table = Table(block, doc)
                for row in table.rows:
                    for cell in row.cells:
                        for p in cell.paragraphs:
                            if p.text.strip():
                                all_paragraphs.append(p)
        return all_paragraphs

    def _get_indentation_level(self, p: Paragraph) -> float:
        indent = p.paragraph_format.left_indent
        return indent.pt if indent else 0.0

    def _parse_hierarchical_text(self, paragraphs: List[Paragraph], req_id: str, req_name: str) -> List[Dict]:
        extracted_items = []
        item_counter = 1
        parent_stack: List[Tuple[float, str]] = []

        for p in paragraphs:
            lines = [line for line in p.text.split('\n') if line.strip()]
            if not lines: continue
            base_indent = self._get_indentation_level(p)

            for line in lines:
                match = re.match(r'^\s*([*â—¦â—‹â€¢Â·â–´-]|[ê°€-í£]\.|[0-9]+\.)\s*(.*)', line)
                if match:
                    bullet, content = match.group(1), match.group(2).strip()
                    current_indent = base_indent + 5
                else:
                    bullet, content = "", line.strip()
                    current_indent = base_indent

                if not content: continue

                while parent_stack and current_indent <= parent_stack[-1][0]:
                    parent_stack.pop()
                
                parent_text = parent_stack[-1][1] if parent_stack else req_name
                
                extracted_items.append({
                    'ìƒìœ„ ìš”êµ¬ì‚¬í•­ ID': req_id, 'ìƒìœ„ ìš”êµ¬ì‚¬í•­ ëª…ì¹­': req_name,
                    'ID': f"{req_id}-{item_counter:03d}", 'ë ˆë²¨': len(parent_stack) + 1,
                    'êµ¬ë¶„(ë¸”ë¦¿)': bullet, 'ë‚´ìš©': content, 'ìƒìœ„ í•­ëª©': parent_text,
                })
                item_counter += 1
                parent_stack.append((current_indent, content))
        return extracted_items

    def process(self, docx_file: io.BytesIO) -> pd.DataFrame:
        doc = docx.Document(docx_file)
        all_paragraphs = self._get_all_paragraphs_in_order(doc)
        all_requirements = []
        
        block_starts = [i for i, p in enumerate(all_paragraphs) if 'ìš”êµ¬ì‚¬í•­ ëª…ì¹­' in p.text or 'ìš”êµ¬ì‚¬í•­ ê³ ìœ ë²ˆí˜¸' in p.text]
        if not block_starts:
            st.warning("ë¬¸ì„œì—ì„œ 'ìš”êµ¬ì‚¬í•­ ëª…ì¹­' ë˜ëŠ” 'ìš”êµ¬ì‚¬í•­ ê³ ìœ ë²ˆí˜¸' í‚¤ì›Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
            
        st.info(f"ì´ {len(block_starts)}ê°œì˜ ìš”êµ¬ì‚¬í•­ ë¸”ë¡ ì‹œì‘ì ì„ ì‹ë³„í–ˆìŠµë‹ˆë‹¤.")

        for i, start_idx in enumerate(block_starts):
            end_idx = block_starts[i+1] if i + 1 < len(block_starts) else len(all_paragraphs)
            block_paragraphs = all_paragraphs[start_idx:end_idx]
            block_text = "\n".join([p.text for p in block_paragraphs])
            
            req_id_match = re.search(r'ìš”êµ¬ì‚¬í•­\s*ê³ ìœ ë²ˆí˜¸\s*[:]?\s*([A-Z0-9-]{3,})', block_text, re.IGNORECASE)
            req_name_match = re.search(r'ìš”êµ¬ì‚¬í•­\s*ëª…ì¹­\s*[:]?\s*(.+?)(?:\n|$)', block_text)
            
            req_id = req_id_match.group(1).strip() if req_id_match else f"REQ-TEMP-{i+1:03d}"
            req_name = req_name_match.group(1).strip() if req_name_match else "ëª…ì¹­ ë¯¸ìƒ"

            details_start_offset = next((j + 1 for j, p in enumerate(block_paragraphs) if 'ì„¸ë¶€ë‚´ìš©' in p.text), -1)
            
            if details_start_offset != -1:
                details_paragraphs = block_paragraphs[details_start_offset:]
                parsed_items = self._parse_hierarchical_text(details_paragraphs, req_id, req_name)
                all_requirements.extend(parsed_items)

        if not all_requirements:
            st.warning("ìš”êµ¬ì‚¬í•­ ë¸”ë¡ì€ ì°¾ì•˜ìœ¼ë‚˜, ì„¸ë¶€ ë‚´ìš©ì„ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë¬¸ì„œ êµ¬ì¡°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return pd.DataFrame()

        df = pd.DataFrame(all_requirements)
        column_order = ['ID', 'ë ˆë²¨', 'ë‚´ìš©', 'ìƒìœ„ í•­ëª©', 'êµ¬ë¶„(ë¸”ë¦¿)', 'ìƒìœ„ ìš”êµ¬ì‚¬í•­ ID', 'ìƒìœ„ ìš”êµ¬ì‚¬í•­ ëª…ì¹­']
        return df.reindex(columns=[col for col in column_order if col in df.columns])

# --- 2ë‹¨ê³„ ë¡œì§: Gemini API ì—°ë™ í´ë˜ìŠ¤ ---
class GeminiProcessor:
    def __init__(self, api_key: str):
        self.api_key = api_key
        try:
            genai.configure(api_key=self.api_key)
            self.model = genai.GenerativeModel('gemini-1.5-flash-latest')
        except Exception as e:
            st.error(f"Gemini API í‚¤ ì„¤ì • ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            self.model = None

    def _format_dataframe_for_llm(self, df: pd.DataFrame) -> str:
        markdown_lines = []
        for _, row in df.iterrows():
            indent = "  " * (row['ë ˆë²¨'] - 1)
            markdown_lines.append(f"{indent}- {row['ë‚´ìš©']}")
        return "\n".join(markdown_lines)

    def reconstruct_requirements(self, df: pd.DataFrame, custom_prompt: str) -> str:
        if not self.model:
            return "ì˜¤ë¥˜: Gemini ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
            
        formatted_text = self._format_dataframe_for_llm(df)
        final_prompt = f"{custom_prompt}\n\n### ì›ë³¸ ì¶”ì¶œ ë°ì´í„° (ê³„ì¸µì  ëª©ë¡):\n{formatted_text}"
        try:
            response = self.model.generate_content(final_prompt)
            return response.text
        except Exception as e:
            return f"Gemini API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

# --- Streamlit UI êµ¬ì„± ---
def main():
    st.set_page_config(page_title="AI ìš”êµ¬ì‚¬í•­ ë¶„ì„ê¸°", layout="wide")
    st.title("ğŸ“‘ AI ê¸°ë°˜ DOCX ìš”êµ¬ì‚¬í•­ ë¶„ì„ ë° ì¬êµ¬ì„±")
    st.markdown("**1ë‹¨ê³„**: DOCX ë¬¸ì„œì—ì„œ ìš”êµ¬ì‚¬í•­ í…ìŠ¤íŠ¸ë¥¼ ê³„ì¸µì ìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.\n"
                "**2ë‹¨ê³„**: ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ Gemini AIë¥¼ ì‚¬ìš©í•˜ì—¬ ëª…í™•í•œ ìš”êµ¬ì‚¬í•­ ëª…ì„¸ë¡œ ì¬êµ¬ì„±í•©ë‹ˆë‹¤.")

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'extracted_df' not in st.session_state:
        st.session_state.extracted_df = pd.DataFrame()
    if 'reconstructed_text' not in st.session_state:
        st.session_state.reconstructed_text = ""

    with st.sidebar:
        st.header("âš™ï¸ 1ë‹¨ê³„: ì¶”ì¶œ ì„¤ì •")
        business_code = st.text_input("ì‚¬ì—… ì½”ë“œ (ID ìƒì„±ìš©)", value="MFDS")
        st.info("ì´ ë„êµ¬ëŠ” ë¸”ë¦¿ ë¬¸ì ì„¤ì • ì—†ì´, ë¬¸ì„œì˜ êµ¬ì¡° ìì²´ë¥¼ ë¶„ì„í•˜ì—¬ ìë™ìœ¼ë¡œ ê³„ì¸µì„ ì¸ì‹í•©ë‹ˆë‹¤.")
        st.markdown("---")
        st.header("âš™ï¸ 2ë‹¨ê³„: AI ì¬êµ¬ì„± ì„¤ì •")
        api_key = st.text_input("Gemini API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.", type="password", help="[Google AI Studio](https://aistudio.google.com/app/apikey)ì—ì„œ API í‚¤ë¥¼ ë°œê¸‰ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    # --- UI ë ˆì´ì•„ì›ƒ ì„¤ì • ---
    col1, col2 = st.columns(2)

    with col1:
        st.header("1ï¸âƒ£ ì›ë³¸ ë¬¸ì„œ ë° ì¶”ì¶œ")
        uploaded_file = st.file_uploader("ë¶„ì„í•  .docx íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["docx"])

        if uploaded_file:
            extractor = AdvancedDocxExtractor(business_code=business_code)
            with st.spinner("1ë‹¨ê³„: ë¬¸ì„œ êµ¬ì¡° ë¶„ì„ ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘..."):
                file_bytes = io.BytesIO(uploaded_file.getvalue())
                st.session_state.extracted_df = extractor.process(file_bytes)
                st.session_state.reconstructed_text = ""

        if not st.session_state.extracted_df.empty:
            st.success(f"âœ… ì´ {len(st.session_state.extracted_df)}ê°œì˜ ìš”êµ¬ì‚¬í•­ í•­ëª©ì„ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
            
            # [ê¸°ëŠ¥ ì¶”ê°€] í•µì‹¬ ê¸°ëŠ¥ ëª©ë¡ ì¶”ì¶œ ë° ë¯¸ë¦¬ë³´ê¸°
            st.subheader("ğŸ“‹ í•µì‹¬ ê¸°ëŠ¥ ëª©ë¡ (ë¯¸ë¦¬ë³´ê¸°)")
            feature_list_df = st.session_state.extracted_df[st.session_state.extracted_df['ë ˆë²¨'] <= 2]
            st.dataframe(feature_list_df.head(5)) # ìƒìœ„ 5ê°œë§Œ í‘œì‹œ

            with st.expander("ì „ì²´ ê¸°ëŠ¥ ëª©ë¡ ë³´ê¸°"):
                st.dataframe(feature_list_df)

            # ì „ì²´ ìƒì„¸ ëª©ë¡ì€ Expander ì•ˆì— ë„£ì–´ì„œ UIë¥¼ ê¹”ë”í•˜ê²Œ ìœ ì§€
            with st.expander("ì „ì²´ ìƒì„¸ ì¶”ì¶œ ëª©ë¡ ë³´ê¸°"):
                st.dataframe(st.session_state.extracted_df)
        
            st.download_button(
                label="ğŸ“¥ ì „ì²´ ì¶”ì¶œ ê²°ê³¼ë¥¼ CSVë¡œ ë‹¤ìš´ë¡œë“œ",
                data=st.session_state.extracted_df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig'),
                file_name=f"extracted_requirements_full_{business_code}.csv",
                mime="text/csv",
            )
    
    with col2:
        st.header("2ï¸âƒ£ AI ì¬êµ¬ì„± ê²°ê³¼")
        if not st.session_state.extracted_df.empty:
            if api_key:
                default_prompt = """ë‹¹ì‹ ì€ IT í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ì— ì œê³µëœ 'ì›ë³¸ ì¶”ì¶œ ë°ì´í„°'ëŠ” RFP ë¬¸ì„œì—ì„œ ê¸°ê³„ì ìœ¼ë¡œ ì¶”ì¶œëœ ê³„ì¸µì  í…ìŠ¤íŠ¸ ëª©ë¡ì…ë‹ˆë‹¤.

                ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ë‹¤ìŒ ì§€ì¹¨ì— ë”°ë¼ ì´ ë°ì´í„°ë¥¼ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ 'ìš”êµ¬ì‚¬í•­ ëª…ì„¸ì„œ'ë¡œ ì¬êµ¬ì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

                1.  **ê·¸ë£¹í™” ë° êµ¬ì¡°í™”**: ì—°ê´€ëœ í•­ëª©ë“¤ì„ ë…¼ë¦¬ì ì¸ ê¸°ëŠ¥ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ê³ , ëª…í™•í•œ ì œëª©ê³¼ ë¶€ì œëª©(ì˜ˆ: `### 1. ì‚¬ìš©ì ê´€ë¦¬`)ì„ ì‚¬ìš©í•˜ì„¸ìš”.
                2.  **ëª…ë£Œí•œ ë¬¸ì¥**: ê° ìš”êµ¬ì‚¬í•­ì€ ëª…í™•í•˜ê³  ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ë‹¤ì‹œ ì‘ì„±í•˜ì„¸ìš”. (ì˜ˆ: "~í•´ì•¼ í•œë‹¤", "~ ê¸°ëŠ¥ì„ ì œê³µí•´ì•¼ í•œë‹¤.")
                3.  **ì „ë¬¸ ìš©ì–´ ì‚¬ìš©**: ì ì ˆí•œ ê²½ìš°, 'ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­', 'ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­', 'ë³´ì•ˆ ìš”êµ¬ì‚¬í•­' ë“± ì „ë¬¸ ìš©ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ìš”êµ¬ì‚¬í•­ì„ ë¶„ë¥˜í•˜ì„¸ìš”.
                4.  **ì¶œë ¥ í˜•ì‹**: ìµœì¢… ê²°ê³¼ë¬¼ì€ ì „ë¬¸ê°€ê°€ ì‘ì„±í•œ ê¸°ìˆ  ë¬¸ì„œì²˜ëŸ¼ ë³´ì´ëŠ” ê¹”ë”í•œ Markdown í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”. (ì œëª©, ê¸€ë¨¸ë¦¬ ê¸°í˜¸, êµµì€ ê¸€ì”¨ ë“±ì„ ì ê·¹ì ìœ¼ë¡œ í™œìš©)
                """
                user_prompt = st.text_area("LLMì—ê²Œ ë‚´ë¦´ ì§€ì‹œì‚¬í•­ (í”„ë¡¬í”„íŠ¸)", value=default_prompt, height=280)

                if st.button("ìš”êµ¬ì‚¬í•­ ì¬êµ¬ì„± ì‹¤í–‰ âœ¨", type="primary"):
                    processor = GeminiProcessor(api_key=api_key)
                    with st.spinner("Gemini AIê°€ ìš”êµ¬ì‚¬í•­ì„ ì¬êµ¬ì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤... (ìµœëŒ€ 1ë¶„ ì†Œìš”)"):
                        st.session_state.reconstructed_text = processor.reconstruct_requirements(st.session_state.extracted_df, user_prompt)
                
                if st.session_state.reconstructed_text:
                    # [ê¸°ëŠ¥ ì¶”ê°€] ì¬êµ¬ì„± ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
                    st.subheader("ğŸ¤– ì¬êµ¬ì„± ê²°ê³¼ (ë¯¸ë¦¬ë³´ê¸°)")
                    preview_lines = st.session_state.reconstructed_text.split('\n')[:15] # ìƒìœ„ 15ì¤„ë§Œ í‘œì‹œ
                    st.markdown("\n".join(preview_lines))
                    st.markdown("...") # ë” ìˆìŒì„ ì•”ì‹œ

                    with st.expander("ì „ì²´ ì¬êµ¬ì„± ê²°ê³¼ ë³´ê¸°"):
                        st.markdown(st.session_state.reconstructed_text)

                    st.download_button(
                        label="ğŸ“¥ ì¬êµ¬ì„± ê²°ê³¼ë¥¼ Markdown íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ",
                        data=st.session_state.reconstructed_text.encode('utf-8-sig'),
                        file_name=f"reconstructed_requirements_{business_code}.md",
                        mime="text/markdown",
                    )
            else:
                st.warning("AI ì¬êµ¬ì„± ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ ì‚¬ì´ë“œë°”ì— Gemini API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            st.info("ë¨¼ì € DOCX íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ìš”êµ¬ì‚¬í•­ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”.")

if __name__ == '__main__':
    main()
