# app.py

import streamlit as st
import re
import pandas as pd
from typing import List, Dict
import docx
from docx.document import Document
from docx.table import Table
import io

# --- ë¡œì§ í´ë˜ìŠ¤ ---
class StreamlitDocxExtractor:
    """
    [ê°œì„ ë¨] ë¬¸ë‹¨ì˜ ìŠ¤íƒ€ì¼ì„ ë¶„ì„í•˜ì—¬ ìë™ ê¸€ë¨¸ë¦¬ ê¸°í˜¸ê¹Œì§€ ì¸ì‹í•˜ëŠ” í´ë˜ìŠ¤.
    'List Paragraph' ìŠ¤íƒ€ì¼ì„ ê°ì§€í•˜ì—¬ ì•ˆì •ì„±ì„ ëŒ€í­ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.
    """
    def __init__(self, business_code: str = "MFDS"):
        self.business_code = business_code

    def _generate_id(self, req_id: str, sequence: int) -> str:
        """ìš”êµ¬ì‚¬í•­ IDë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        req_type_code = "F" if req_id.startswith("FUN") else "Q"
        id_num_match = re.search(r'\d+', req_id)
        id_num = id_num_match.group(0) if id_num_match else "000"
        return f"REQ-{self.business_code}-{req_type_code}-{id_num}{sequence:03d}"

    def _is_bullet_paragraph(self, p: docx.text.paragraph.Paragraph, bullet_chars: str) -> bool:
        """
        ë¬¸ë‹¨ì´ ì£¼ì–´ì§„ ë¸”ë¦¿ ë¬¸ìë¡œ ì‹œì‘í•˜ê±°ë‚˜, ìë™ ê¸€ë¨¸ë¦¬ ê¸°í˜¸ ìŠ¤íƒ€ì¼ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤.
        """
        line_text = p.text.strip()
        # 1. 'List Paragraph' ìŠ¤íƒ€ì¼ì¸ì§€ í™•ì¸ (ê°€ì¥ í™•ì‹¤í•œ ë°©ë²•)
        if 'List' in p.style.name:
            return True
        # 2. í…ìŠ¤íŠ¸ê°€ ì§ì ‘ ì…ë ¥ëœ ë¸”ë¦¿ ë¬¸ìë¡œ ì‹œì‘í•˜ëŠ”ì§€ í™•ì¸
        if line_text and re.match(f'^[{re.escape(bullet_chars)}]', line_text):
            return True
        return False
    
    def _parse_details_from_paragraphs(self, doc: Document, start_idx: int, end_idx: int, req_id: str, level1_bullets: str, level2_bullets: str) -> List[Dict]:
        """
        [í•µì‹¬ ë¡œì§] ë¬¸ë‹¨ ë¦¬ìŠ¤íŠ¸ë¥¼ ìˆœíšŒí•˜ë©° ê³„ì¸µì  ìš”êµ¬ì‚¬í•­ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
        """
        final_requirements = []
        bfn_seq_counter = 1
        current_group_title = ""
        
        # 'ì„¸ë¶€ë‚´ìš©' ë°”ë¡œ ë‹¤ìŒ ë¬¸ë‹¨ë¶€í„° ë¸”ë¡ ëê¹Œì§€ ìˆœíšŒ
        for i in range(start_idx, end_idx):
            p = doc.paragraphs[i]
            line = p.text.strip()
            if not line:
                continue

            # 1ì°¨ ë¸”ë¦¿ì¸ì§€ í™•ì¸ (ìŠ¤íƒ€ì¼ ë˜ëŠ” í…ìŠ¤íŠ¸ ê¸°ë°˜)
            if self._is_bullet_paragraph(p, level1_bullets):
                current_group_title = re.sub(f'^[{re.escape(level1_bullets)}]+\s*', '', line)
                
                # ë‹¤ìŒ ë¬¸ë‹¨ì´ 2ì°¨ ë¸”ë¦¿ì¸ì§€ ë¯¸ë¦¬ í™•ì¸
                is_next_l2 = False
                if i + 1 < end_idx:
                    next_p = doc.paragraphs[i+1]
                    if self._is_bullet_paragraph(next_p, level2_bullets):
                        is_next_l2 = True
                
                # 2ì°¨ ë¸”ë¦¿ì´ ì—†ëŠ” ë‹¨ë… 1ì°¨ ë¸”ë¦¿ì´ë©´, ê·¸ ìì²´ê°€ ìš”êµ¬ì‚¬í•­
                if not is_next_l2:
                    final_requirements.append({
                        'ìš”êµ¬ì‚¬í•­ ê·¸ë£¹': current_group_title, 'ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ë‚´ìš©': current_group_title,
                        'ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ID': self._generate_id(req_id, bfn_seq_counter)
                    })
                    bfn_seq_counter += 1
                    
            # 2ì°¨ ë¸”ë¦¿ì¸ì§€ í™•ì¸í•˜ê³ , í˜„ì¬ ê·¸ë£¹ì— ì†í•´ìˆëŠ”ì§€ í™•ì¸
            elif current_group_title and self._is_bullet_paragraph(p, level2_bullets):
                point_text = re.sub(f'^\s*[{re.escape(level2_bullets)}]+\s*', '', line)
                final_requirements.append({
                    'ìš”êµ¬ì‚¬í•­ ê·¸ë£¹': current_group_title, 'ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ë‚´ìš©': point_text,
                    'ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ID': self._generate_id(req_id, bfn_seq_counter)
                })
                bfn_seq_counter += 1
        
        return final_requirements

    def process(self, docx_file: io.BytesIO, level1_bullets: str, level2_bullets: str) -> pd.DataFrame:
        """
        [ìˆ˜ì •ë¨] Paragraph ê°ì²´ ê¸°ë°˜ì˜ ìƒˆë¡œìš´ íŒŒì‹± ë¡œì§ì„ ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì •
        """
        doc = docx.Document(docx_file)
        
        # í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ 'ìš”êµ¬ì‚¬í•­ ë¸”ë¡'ì˜ ì‹œì‘ê³¼ ë ìœ„ì¹˜(ë¬¸ë‹¨ ì¸ë±ìŠ¤)ë¥¼ ë¨¼ì € ì°¾ìŒ
        block_markers = []
        for i, p in enumerate(doc.paragraphs):
            # 'ìš”êµ¬ì‚¬í•­ ë¶„ë¥˜' í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ë‹¨ì„ ë¸”ë¡ì˜ ì‹œì‘ìœ¼ë¡œ ê°„ì£¼
            if 'ìš”êµ¬ì‚¬í•­ ë¶„ë¥˜' in p.text:
                block_markers.append(i)
        
        st.info(f"ì´ {len(block_markers)}ê°œì˜ ìš”êµ¬ì‚¬í•­ ë¸”ë¡ ì‹œì‘ì ì„ ì‹ë³„í–ˆìŠµë‹ˆë‹¤.")
        if not block_markers:
            st.warning("ë¬¸ì„œì—ì„œ 'ìš”êµ¬ì‚¬í•­ ë¶„ë¥˜' í‚¤ì›Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¬¸ì„œ êµ¬ì¡°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return pd.DataFrame()

        all_requirements = []
        # ê° ìš”êµ¬ì‚¬í•­ ë¸”ë¡ë³„ë¡œ ì²˜ë¦¬
        for i, start_index in enumerate(block_markers):
            # í˜„ì¬ ë¸”ë¡ì˜ ë ì¸ë±ìŠ¤ ê³„ì‚° (ë‹¤ìŒ ë¸”ë¡ ì‹œì‘ ì „ê¹Œì§€)
            end_index = block_markers[i+1] if i + 1 < len(block_markers) else len(doc.paragraphs)
            
            # í˜„ì¬ ë¸”ë¡ì— í¬í•¨ëœ ë¬¸ë‹¨ë“¤ì˜ í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹¨
            block_text = "\n".join([p.text for p in doc.paragraphs[start_index:end_index]])
            
            # ë¸”ë¡ ë‚´ì—ì„œ IDì™€ ëª…ì¹­ ì¶”ì¶œ
            req_id_match = re.search(r'ìš”êµ¬ì‚¬í•­ ê³ ìœ ë²ˆí˜¸\s+([A-Z]{3}-\d{3})', block_text)
            req_name_match = re.search(r'ìš”êµ¬ì‚¬í•­ ëª…ì¹­\s+(.+?)(?:\n|$)', block_text)

            if not req_id_match or not req_name_match: continue

            req_id, req_name = req_id_match.group(1).strip(), req_name_match.group(1).strip()
            
            # 'ì„¸ë¶€ë‚´ìš©' í‚¤ì›Œë“œê°€ ìˆëŠ” ë¬¸ë‹¨ ì¸ë±ìŠ¤ë¥¼ ì°¾ì•„ íŒŒì‹± ì‹œì‘ì ìœ¼ë¡œ ì„¤ì •
            details_start_index = -1
            for j in range(start_index, end_index):
                if 'ì„¸ë¶€ë‚´ìš©' in doc.paragraphs[j].text:
                    details_start_index = j + 1 # ì„¸ë¶€ë‚´ìš© ë°”ë¡œ ë‹¤ìŒ ë¬¸ë‹¨ë¶€í„°
                    break
            
            if details_start_index != -1:
                # ìŠ¤íƒ€ì¼ ê¸°ë°˜ íŒŒì„œ í˜¸ì¶œ
                parsed_reqs = self._parse_details_from_paragraphs(doc, details_start_index, end_index, req_id, level1_bullets, level2_bullets)
                for req in parsed_reqs:
                    req['ìš”êµ¬ì‚¬í•­ ID (RFP ì›ì²œ)'] = req_id
                    req['ìš”êµ¬ì‚¬í•­ ëª…ì¹­ (RFP ì›ì²œ)'] = req_name
                all_requirements.extend(parsed_reqs)

        if not all_requirements:
            st.warning("ìš”êµ¬ì‚¬í•­ ë¸”ë¡ì€ ì°¾ì•˜ìœ¼ë‚˜, ì„¸ë¶€ ë‚´ìš©ì„ íŒŒì‹±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë¬¸ì„œ êµ¬ì¡°ë‚˜ ë¸”ë¦¿ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return pd.DataFrame()

        df = pd.DataFrame(all_requirements)
        df['ì¶œì²˜'] = 'DOCX ë¬¸ì„œ'
        df['ìœ í˜•'] = df['ìš”êµ¬ì‚¬í•­ ID (RFP ì›ì²œ)'].apply(lambda x: 'ê¸°ëŠ¥' if x.startswith('FUN') else 'ë¹„ê¸°ëŠ¥')
        
        column_order = [
            'ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ID', 'ìš”êµ¬ì‚¬í•­ ê·¸ë£¹', 'ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ë‚´ìš©', 
            'ìš”êµ¬ì‚¬í•­ ID (RFP ì›ì²œ)', 'ìš”êµ¬ì‚¬í•­ ëª…ì¹­ (RFP ì›ì²œ)', 'ìœ í˜•', 'ì¶œì²˜'
        ]
        return df.reindex(columns=column_order)

# --- Streamlit UI êµ¬ì„± ---
def main():
    st.set_page_config(page_title="ìš”êµ¬ì‚¬í•­ ì¶”ì¶œê¸°", layout="wide", initial_sidebar_state="expanded")
    st.title("ğŸ“„ DOCX ìš”êµ¬ì‚¬í•­ ì •ì˜ì„œ ìë™ ì¶”ì¶œê¸°")
    st.markdown("MS Wordì˜ ìë™ ê¸€ë¨¸ë¦¬ ê¸°í˜¸(`-`, `*` ë“±)ë¥¼ í¬í•¨í•œ ìš”êµ¬ì‚¬í•­ ì •ì˜ì„œë¥¼ ë¶„ì„í•˜ì—¬ ì„¸ë¶€ ëª©ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤.")

    with st.sidebar:
        st.header("âš™ï¸ ë¶„ì„ ì„¤ì •")
        
        business_code = st.text_input("ì‚¬ì—… ì½”ë“œ", value="MFDS", help="ìš”êµ¬ì‚¬í•­ ID ìƒì„±ì— ì‚¬ìš©ë©ë‹ˆë‹¤. (ì˜ˆ: REQ-**MFDS**-F-001001)")
        
        st.markdown("---")
        
        st.subheader("ë¸”ë¦¿(Bullet) ì²´ê³„ ì„¤ì •")
        level1_bullets = st.text_input("1ì°¨ ë¸”ë¦¿ ë¬¸ì (ê·¸ë£¹)", value="â—¦â—‹â€¢", help="ìš”êµ¬ì‚¬í•­ ê·¸ë£¹ì„ ë‚˜íƒ€ë‚´ëŠ” ê¸€ë¨¸ë¦¬ ê¸°í˜¸ë¥¼ ëª¨ë‘ ì…ë ¥í•˜ì„¸ìš”.")
        level2_bullets = st.text_input("2ì°¨ ë¸”ë¦¿ ë¬¸ì (ì„¸ë¶€ í•­ëª©)", value="-*Â·â–´", help="ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ì„ ë‚˜íƒ€ë‚´ëŠ” ê¸€ë¨¸ë¦¬ ê¸°í˜¸ë¥¼ ëª¨ë‘ ì…ë ¥í•˜ì„¸ìš”.")
        st.info("ë¬¸ì„œì— ì‚¬ìš©ëœ ë¸”ë¦¿ì„ ì •í™•íˆ ì…ë ¥í•´ì•¼ ë¶„ì„ ì„±ê³µë¥ ì´ ë†’ì•„ì§‘ë‹ˆë‹¤.")

    uploaded_file = st.file_uploader("ë¶„ì„í•  .docx íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["docx"])

    if uploaded_file is not None:
        try:
            extractor = StreamlitDocxExtractor(business_code=business_code)
            
            with st.spinner("íŒŒì¼ ë¶„ì„ ë° ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ ì¤‘..."):
                requirements_df = extractor.process(uploaded_file, level1_bullets, level2_bullets)

            if not requirements_df.empty:
                st.success(f"âœ… ì´ {len(requirements_df)}ê°œì˜ ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ì„ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
                st.dataframe(requirements_df)

                @st.cache_data
                def convert_df_to_csv(_df):
                    return _df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')

                csv_data = convert_df_to_csv(requirements_df)
                
                st.download_button(
                    label="ğŸ“¥ ì¶”ì¶œ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ",
                    data=csv_data,
                    file_name=f"extracted_requirements_{business_code}.csv",
                    mime="text/csv",
                )
            else:
                pass # ê²½ê³  ë©”ì‹œì§€ëŠ” process() í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì´ë¯¸ ì²˜ë¦¬ë¨

        except Exception as e:
            st.error(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            st.exception(e) # ê°œë°œì í™•ì¸ìš© ìƒì„¸ ì—ëŸ¬ ë¡œê·¸

if __name__ == '__main__':
    main()
