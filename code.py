# app.py

import streamlit as st
import re
import pandas as pd
from typing import List, Dict
import docx
from docx.document import Document
from docx.table import Table
from docx.text.paragraph import Paragraph
import io

# --- ë¡œì§ í´ë˜ìŠ¤ ---
class StreamlitDocxExtractor:
    """
    [ìµœì¢… ì™„ì„±ë³¸] ì¼ë°˜ ë¬¸ë‹¨, í‘œ(Table), ë‹¤ì–‘í•œ ë¸”ë¦¿ ê³„ì¸µ êµ¬ì¡°ë¥¼ ëª¨ë‘ ì²˜ë¦¬í•˜ëŠ” í´ë˜ìŠ¤.
    """
    def __init__(self, business_code: str = "MFDS"):
        self.business_code = business_code

    def _generate_id(self, req_id: str, sequence: int) -> str:
        """ìš”êµ¬ì‚¬í•­ IDë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        req_type_code = "F" if req_id.startswith("FUN") else "Q"
        id_num_match = re.search(r'\d+', req_id)
        id_num = id_num_match.group(0) if id_num_match else "000"
        return f"REQ-{self.business_code}-{req_type_code}-{id_num}{sequence:03d}"

    def _get_all_paragraphs_in_order(self, doc: Document) -> List[Paragraph]:
        """
        ë¬¸ì„œì˜ ëª¨ë“  ë¬¸ë‹¨ ê°ì²´ë¥¼ í‘œ ì•ˆì˜ ë‚´ìš©ê¹Œì§€ í¬í•¨í•˜ì—¬ ìˆœì„œëŒ€ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.
        """
        all_paragraphs = []
        for block in doc.element.body:
            if isinstance(block, docx.oxml.text.paragraph.CT_P):
                all_paragraphs.append(Paragraph(block, doc))
            elif isinstance(block, docx.oxml.table.CT_Tbl):
                table = Table(block, doc)
                for row in table.rows:
                    for cell in row.cells:
                        for para in cell.paragraphs:
                            all_paragraphs.append(para)
        return all_paragraphs

    def _is_bullet_paragraph(self, p: Paragraph, bullet_chars: str) -> bool:
        """
        ë¬¸ë‹¨ì´ ì£¼ì–´ì§„ ë¸”ë¦¿ ë¬¸ìë¡œ ì‹œì‘í•˜ê±°ë‚˜, ìë™ ê¸€ë¨¸ë¦¬ ê¸°í˜¸ ìŠ¤íƒ€ì¼ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤.
        """
        line_text = p.text.strip()
        if not line_text:
            return False
        if p.style and 'List' in p.style.name:
            return True
        if re.match(f'^[{re.escape(bullet_chars)}]', line_text):
            return True
        return False
    
    def _parse_details_from_paragraphs(self, paragraphs: List[Paragraph], req_id: str, level1_bullets: str, level2_bullets: str) -> List[Dict]:
        """
        [ìˆ˜ì •ë¨] ê³„ì¸µ êµ¬ì¡° ì¸ì‹ ë¡œì§ì„ ê°œì„ í•˜ì—¬ ë‹¨ì¼ ë ˆë²¨ ë¸”ë¦¿ë„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        """
        final_requirements = []
        bfn_seq_counter = 1
        current_group_title = ""
        
        # ì„ì‹œ ë²„í¼: 1ì°¨ ë¸”ë¦¿ì´ ê·¸ë£¹ ì œëª©ì¸ì§€ ë‹¨ë… ìš”êµ¬ì‚¬í•­ì¸ì§€ íŒë‹¨í•˜ê¸° ìœ„í•´ ì‚¬ìš©
        temp_group_buffer = None

        def flush_buffer():
            """ë²„í¼ì— ì €ì¥ëœ ì´ì „ ê·¸ë£¹ ì •ë³´ë¥¼ ìµœì¢… ê²°ê³¼ì— ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜"""
            nonlocal bfn_seq_counter
            if temp_group_buffer:
                final_requirements.append({
                    'ìš”êµ¬ì‚¬í•­ ê·¸ë£¹': temp_group_buffer['title'],
                    'ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ë‚´ìš©': temp_group_buffer['title'], # 2ì°¨ ë¸”ë¦¿ì´ ì—†ì—ˆìœ¼ë¯€ë¡œ ê·¸ë£¹ëª…ê³¼ ë‚´ìš©ì´ ë™ì¼
                    'ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ID': self._generate_id(req_id, bfn_seq_counter)
                })
                bfn_seq_counter += 1
                
        for p in paragraphs:
            line = p.text.strip()
            if not line:
                continue

            is_level1 = self._is_bullet_paragraph(p, level1_bullets)
            is_level2 = self._is_bullet_paragraph(p, level2_bullets)

            # 1. 1ì°¨ ë¸”ë¦¿ì„ ë§Œë‚œ ê²½ìš°
            if is_level1:
                # ì´ì „ì— ì²˜ë¦¬ë˜ì§€ ì•Šì€ 1ì°¨ ë¸”ë¦¿ ê·¸ë£¹ì´ ìˆì—ˆë‹¤ë©´ ë¨¼ì € ê²°ê³¼ì— ì¶”ê°€
                flush_buffer()
                
                # í˜„ì¬ 1ì°¨ ë¸”ë¦¿ì„ ìƒˆë¡œìš´ ê·¸ë£¹ í›„ë³´ë¡œ ë²„í¼ì— ì €ì¥
                current_group_title = re.sub(f'^[{re.escape(level1_bullets)}]+\s*', '', line)
                temp_group_buffer = {'title': current_group_title}

            # 2. 2ì°¨ ë¸”ë¦¿ì„ ë§Œë‚œ ê²½ìš°
            elif is_level2 and current_group_title:
                # 2ì°¨ ë¸”ë¦¿ì´ ë‚˜íƒ€ë‚¬ë‹¤ëŠ” ê²ƒì€, ë²„í¼ì˜ 1ì°¨ ë¸”ë¦¿ì´ ê·¸ë£¹ ì œëª©ì´ ë§ë‹¤ëŠ” ì˜ë¯¸
                temp_group_buffer = None # ë²„í¼ë¥¼ ë¹„ì›Œ ì¤‘ë³µ ì¶”ê°€ ë°©ì§€
                
                point_text = re.sub(f'^\s*[{re.escape(level2_bullets)}]+\s*', '', line)
                final_requirements.append({
                    'ìš”êµ¬ì‚¬í•­ ê·¸ë£¹': current_group_title,
                    'ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ë‚´ìš©': point_text,
                    'ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ID': self._generate_id(req_id, bfn_seq_counter)
                })
                bfn_seq_counter += 1
            
            # 3. ë¸”ë¦¿ì´ ì•„ë‹Œ ì¼ë°˜ í…ìŠ¤íŠ¸ê°€ ê·¸ë£¹ì— ì†í•œ ê²½ìš° (2ì°¨ ë¸”ë¦¿ ì²˜ëŸ¼ ì·¨ê¸‰)
            elif not is_level1 and not is_level2 and temp_group_buffer:
                # ë²„í¼ì— ìˆëŠ” 1ì°¨ ë¸”ë¦¿ì„ ê·¸ë£¹ìœ¼ë¡œ í™•ì •
                current_group_title = temp_group_buffer['title']
                temp_group_buffer = None

                final_requirements.append({
                    'ìš”êµ¬ì‚¬í•­ ê·¸ë£¹': current_group_title,
                    'ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ë‚´ìš©': line, # ì¼ë°˜ í…ìŠ¤íŠ¸ ë¼ì¸
                    'ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ID': self._generate_id(req_id, bfn_seq_counter)
                })
                bfn_seq_counter +=1


        # ë£¨í”„ê°€ ëë‚œ í›„, ë§ˆì§€ë§‰ìœ¼ë¡œ ë²„í¼ì— ë‚¨ì•„ìˆëŠ” 1ì°¨ ë¸”ë¦¿ ì²˜ë¦¬
        flush_buffer()
        
        return final_requirements


    def process(self, docx_file: io.BytesIO, level1_bullets: str, level2_bullets: str) -> pd.DataFrame:
        """
        ë¬¸ì„œ ì „ì²´ë¥¼ ìˆœíšŒí•˜ë©° í‘œ ë‚´ë¶€ë¥¼ í¬í•¨í•œ ëª¨ë“  ìš”êµ¬ì‚¬í•­ì„ ë¶„ì„í•©ë‹ˆë‹¤.
        """
        doc = docx.Document(docx_file)
        
        all_paragraphs = self._get_all_paragraphs_in_order(doc)
        
        block_markers = []
        for i, p in enumerate(all_paragraphs):
            if 'ìš”êµ¬ì‚¬í•­ ë¶„ë¥˜' in p.text:
                block_markers.append(i)
        
        st.info(f"ì´ {len(block_markers)}ê°œì˜ ìš”êµ¬ì‚¬í•­ ë¸”ë¡ ì‹œì‘ì ì„ ì‹ë³„í–ˆìŠµë‹ˆë‹¤.")
        if not block_markers:
            st.warning("ë¬¸ì„œì—ì„œ 'ìš”êµ¬ì‚¬í•­ ë¶„ë¥˜' í‚¤ì›Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        all_requirements = []
        for i, start_index in enumerate(block_markers):
            end_index = block_markers[i+1] if i + 1 < len(block_markers) else len(all_paragraphs)
            
            block_paragraphs = all_paragraphs[start_index:end_index]
            block_text = "\n".join([p.text for p in block_paragraphs])
            
            req_id_match = re.search(r'ìš”êµ¬ì‚¬í•­ ê³ ìœ ë²ˆí˜¸\s+([A-Z]{3}-\d{3})', block_text)
            req_name_match = re.search(r'ìš”êµ¬ì‚¬í•­ ëª…ì¹­\s+(.+?)(?:\n|$)', block_text)

            if not req_id_match or not req_name_match: continue

            req_id, req_name = req_id_match.group(1).strip(), req_name_match.group(1).strip()
            
            details_start_index_offset = -1
            for j, p in enumerate(block_paragraphs):
                if 'ì„¸ë¶€ë‚´ìš©' in p.text:
                    details_start_index_offset = j + 1
                    break
            
            if details_start_index_offset != -1:
                details_paragraphs = block_paragraphs[details_start_index_offset:]
                parsed_reqs = self._parse_details_from_paragraphs(details_paragraphs, req_id, level1_bullets, level2_bullets)
                
                for req in parsed_reqs:
                    req['ìš”êµ¬ì‚¬í•­ ID (RFP ì›ì²œ)'] = req_id
                    req['ìš”êµ¬ì‚¬í•­ ëª…ì¹­ (RFP ì›ì²œ)'] = req_name
                all_requirements.extend(parsed_reqs)

        if not all_requirements:
            st.warning("ìš”êµ¬ì‚¬í•­ ë¸”ë¡ì€ ì°¾ì•˜ìœ¼ë‚˜, ì„¸ë¶€ ë‚´ìš©ì„ íŒŒì‹±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë¬¸ì„œ êµ¬ì¡°ë‚˜ ë¸”ë¦¿ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return pd.DataFrame()

        df = pd.DataFrame(all_requirements)
        df['ì¶œì²˜'] = 'DOCX ë¬¸ì„œ'
        df['ìœ í˜•'] = df['ìš”êµ¬ì‚¬í•­ ID (RFP ì›ì²œ)'].apply(lambda x: 'ê¸°ëŠ¥' if x.startswith('FUN') else 'ë¹„ê¸°ëŠ¥')
        
        column_order = [
            'ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ID', 'ìš”êµ¬ì‚¬í•­ ê·¸ë£¹', 'ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ë‚´ìš©', 
            'ìš”êµ¬ì‚¬í•­ ID (RFP ì›ì²œ)', 'ìš”êµ¬ì‚¬í•­ ëª…ì¹­ (RFP ì›ì²œ)', 'ìœ í˜•', 'ì¶œì²˜'
        ]
        return df.reindex(columns=column_order)

# --- Streamlit UI êµ¬ì„± ---
def main():
    st.set_page_config(page_title="ìš”êµ¬ì‚¬í•­ ì¶”ì¶œê¸°", layout="wide", initial_sidebar_state="expanded")
    st.title("ğŸ“„ DOCX ìš”êµ¬ì‚¬í•­ ì •ì˜ì„œ ìë™ ì¶”ì¶œê¸°")
    st.markdown("MS Wordì˜ ìë™ ê¸€ë¨¸ë¦¬ ê¸°í˜¸ ë° **í‘œ(Table)ì— í¬í•¨ëœ ë‚´ìš©**ê¹Œì§€ ë¶„ì„í•˜ì—¬ ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ëª©ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤.")

    with st.sidebar:
        st.header("âš™ï¸ ë¶„ì„ ì„¤ì •")
        
        business_code = st.text_input("ì‚¬ì—… ì½”ë“œ", value="MFDS", help="ìš”êµ¬ì‚¬í•­ ID ìƒì„±ì— ì‚¬ìš©ë©ë‹ˆë‹¤. (ì˜ˆ: REQ-**MFDS**-F-001001)")
        
        st.markdown("---")
        
        st.subheader("ë¸”ë¦¿(Bullet) ì²´ê³„ ì„¤ì •")
        level1_bullets = st.text_input("1ì°¨ ë¸”ë¦¿ ë¬¸ì (ê·¸ë£¹)", value="*â—¦â—‹â€¢", help="ìš”êµ¬ì‚¬í•­ ê·¸ë£¹ì„ ë‚˜íƒ€ë‚´ëŠ” ê¸€ë¨¸ë¦¬ ê¸°í˜¸ë¥¼ ëª¨ë‘ ì…ë ¥í•˜ì„¸ìš”.")
        level2_bullets = st.text_input("2ì°¨ ë¸”ë¦¿ ë¬¸ì (ì„¸ë¶€ í•­ëª©)", value="-Â·â–´", help="ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ì„ ë‚˜íƒ€ë‚´ëŠ” ê¸€ë¨¸ë¦¬ ê¸°í˜¸ë¥¼ ëª¨ë‘ ì…ë ¥í•˜ì„¸ìš”.")
        st.info("ë¬¸ì„œì— ì‚¬ìš©ëœ ë¸”ë¦¿ì„ ì •í™•íˆ ì…ë ¥í•´ì•¼ ë¶„ì„ ì„±ê³µë¥ ì´ ë†’ì•„ì§‘ë‹ˆë‹¤.")

    uploaded_file = st.file_uploader("ë¶„ì„í•  .docx íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["docx"])

    if uploaded_file is not None:
        try:
            extractor = StreamlitDocxExtractor(business_code=business_code)
            
            with st.spinner("íŒŒì¼ ë¶„ì„ ë° ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ ì¤‘... (í‘œ/ê³„ì¸µ êµ¬ì¡° í¬í•¨)"):
                requirements_df = extractor.process(uploaded_file, level1_bullets, level2_bullets)

            if not requirements_df.empty:
                st.success(f"âœ… ì´ {len(requirements_df)}ê°œì˜ ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ì„ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
                st.dataframe(requirements_df)

                @st.cache_data
                def convert_df_to_csv(_df):
                    return _df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')

                csv_data = convert_df_to_csv(requirements_df)
                
                st.download_button(
                    label="ğŸ“¥ ì¶”ì¶œ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ",
                    data=csv_data,
                    file_name=f"extracted_requirements_{business_code}.csv",
                    mime="text/csv",
                )
            else:
                pass

        except Exception as e:
            st.error(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            st.exception(e)

if __name__ == '__main__':
    main()
