# app.py

import streamlit as st
import re
import pandas as pd
from typing import List, Dict, Tuple
import docx
from docx.document import Document
from docx.table import Table
from docx.text.paragraph import Paragraph
import io
import google.generativeai as genai

# --- 1ë‹¨ê³„ ë¡œì§: í…ìŠ¤íŠ¸ ì¶”ì¶œê¸° (ì´ì „ê³¼ ë™ì¼) ---
class AdvancedDocxExtractor:
    def __init__(self, business_code: str = "MFDS"):
        self.business_code = business_code

    def _get_all_paragraphs_in_order(self, doc: Document) -> List[Paragraph]:
        all_paragraphs = []
        for block in doc.element.body:
            if isinstance(block, docx.oxml.text.paragraph.CT_P):
                all_paragraphs.append(Paragraph(block, doc))
            elif isinstance(block, docx.oxml.table.CT_Tbl):
                table = Table(block, doc)
                for row in table.rows:
                    for cell in row.cells:
                        for p in cell.paragraphs:
                            if p.text.strip():
                                all_paragraphs.append(p)
        return all_paragraphs

    def _get_indentation_level(self, p: Paragraph) -> float:
        indent = p.paragraph_format.left_indent
        return indent.pt if indent else 0.0

    def _parse_hierarchical_text(self, paragraphs: List[Paragraph], req_id: str, req_name: str) -> List[Dict]:
        extracted_items = []
        item_counter = 1
        parent_stack: List[Tuple[float, str]] = []

        for p in paragraphs:
            lines = [line for line in p.text.split('\n') if line.strip()]
            if not lines: continue
            base_indent = self._get_indentation_level(p)

            for line in lines:
                match = re.match(r'^\s*([*â—¦â—‹â€¢Â·â–´-]|[ê°€-í£]\.|[0-9]+\.)\s*(.*)', line)
                if match:
                    bullet, content = match.group(1), match.group(2).strip()
                    current_indent = base_indent + 5
                else:
                    bullet, content = "", line.strip()
                    current_indent = base_indent

                if not content: continue

                while parent_stack and current_indent <= parent_stack[-1][0]:
                    parent_stack.pop()
                
                parent_text = parent_stack[-1][1] if parent_stack else req_name
                
                extracted_items.append({
                    'ìƒìœ„ ìš”êµ¬ì‚¬í•­ ID': req_id, 'ìƒìœ„ ìš”êµ¬ì‚¬í•­ ëª…ì¹­': req_name,
                    'ID': f"{req_id}-{item_counter:03d}", 'ë ˆë²¨': len(parent_stack) + 1,
                    'êµ¬ë¶„(ë¸”ë¦¿)': bullet, 'ë‚´ìš©': content, 'ìƒìœ„ í•­ëª©': parent_text,
                })
                item_counter += 1
                parent_stack.append((current_indent, content))
        return extracted_items

    def process(self, docx_file: io.BytesIO) -> pd.DataFrame:
        doc = docx.Document(docx_file)
        all_paragraphs = self._get_all_paragraphs_in_order(doc)
        all_requirements = []
        
        block_starts = [i for i, p in enumerate(all_paragraphs) if 'ìš”êµ¬ì‚¬í•­ ëª…ì¹­' in p.text or 'ìš”êµ¬ì‚¬í•­ ê³ ìœ ë²ˆí˜¸' in p.text]
        if not block_starts:
            st.warning("ë¬¸ì„œì—ì„œ 'ìš”êµ¬ì‚¬í•­ ëª…ì¹­' ë˜ëŠ” 'ìš”êµ¬ì‚¬í•­ ê³ ìœ ë²ˆí˜¸' í‚¤ì›Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
            
        st.info(f"ì´ {len(block_starts)}ê°œì˜ ìš”êµ¬ì‚¬í•­ ë¸”ë¡ ì‹œì‘ì ì„ ì‹ë³„í–ˆìŠµë‹ˆë‹¤.")

        for i, start_idx in enumerate(block_starts):
            end_idx = block_starts[i+1] if i + 1 < len(block_starts) else len(all_paragraphs)
            block_paragraphs = all_paragraphs[start_idx:end_idx]
            block_text = "\n".join([p.text for p in block_paragraphs])
            
            req_id_match = re.search(r'ìš”êµ¬ì‚¬í•­\s*ê³ ìœ ë²ˆí˜¸\s*[:]?\s*([A-Z0-9-]{3,})', block_text, re.IGNORECASE)
            req_name_match = re.search(r'ìš”êµ¬ì‚¬í•­\s*ëª…ì¹­\s*[:]?\s*(.+?)(?:\n|$)', block_text)
            
            req_id = req_id_match.group(1).strip() if req_id_match else f"REQ-TEMP-{i+1:03d}"
            req_name = req_name_match.group(1).strip() if req_name_match else "ëª…ì¹­ ë¯¸ìƒ"

            details_start_offset = next((j + 1 for j, p in enumerate(block_paragraphs) if 'ì„¸ë¶€ë‚´ìš©' in p.text), -1)
            
            if details_start_offset != -1:
                details_paragraphs = block_paragraphs[details_start_offset:]
                parsed_items = self._parse_hierarchical_text(details_paragraphs, req_id, req_name)
                all_requirements.extend(parsed_items)

        if not all_requirements:
            st.warning("ìš”êµ¬ì‚¬í•­ ë¸”ë¡ì€ ì°¾ì•˜ìœ¼ë‚˜, ì„¸ë¶€ ë‚´ìš©ì„ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë¬¸ì„œ êµ¬ì¡°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return pd.DataFrame()

        df = pd.DataFrame(all_requirements)
        column_order = ['ID', 'ë ˆë²¨', 'ë‚´ìš©', 'ìƒìœ„ í•­ëª©', 'êµ¬ë¶„(ë¸”ë¦¿)', 'ìƒìœ„ ìš”êµ¬ì‚¬í•­ ID', 'ìƒìœ„ ìš”êµ¬ì‚¬í•­ ëª…ì¹­']
        return df.reindex(columns=[col for col in column_order if col in df.columns])

# --- 2ë‹¨ê³„ ë¡œì§: Gemini API ì—°ë™ í´ë˜ìŠ¤ ---
class GeminiProcessor:
    def __init__(self, api_key: str):
        self.api_key = api_key
        genai.configure(api_key=self.api_key)
        self.model = genai.GenerativeModel('gemini-1.5-pro-latest')

    def _format_dataframe_for_llm(self, df: pd.DataFrame) -> str:
        """DataFrameì„ LLMì´ ì´í•´í•˜ê¸° ì¢‹ì€ ê³„ì¸µì  Markdown í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        markdown_lines = []
        for _, row in df.iterrows():
            # ë ˆë²¨ì— ë”°ë¼ ë“¤ì—¬ì“°ê¸° ì ìš©
            indent = "  " * (row['ë ˆë²¨'] - 1)
            markdown_lines.append(f"{indent}- {row['ë‚´ìš©']}")
        return "\n".join(markdown_lines)

    def reconstruct_requirements(self, df: pd.DataFrame, custom_prompt: str) -> str:
        """ì¶”ì¶œëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì œë¯¸ë‚˜ì´ë¥¼ í˜¸ì¶œí•˜ì—¬ ìš”êµ¬ì‚¬í•­ì„ ì¬êµ¬ì„±"""
        formatted_text = self._format_dataframe_for_llm(df)
        
        final_prompt = f"""{custom_prompt}

### ì›ë³¸ ì¶”ì¶œ ë°ì´í„°:
{formatted_text}
"""
        try:
            response = self.model.generate_content(final_prompt)
            return response.text
        except Exception as e:
            return f"Gemini API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"


# --- Streamlit UI êµ¬ì„± ---
def main():
    st.set_page_config(page_title="AI ìš”êµ¬ì‚¬í•­ ë¶„ì„ê¸°", layout="wide")
    st.title("ğŸ“‘ AI ê¸°ë°˜ DOCX ìš”êµ¬ì‚¬í•­ ë¶„ì„ ë° ì¬êµ¬ì„±")
    st.markdown("**1ë‹¨ê³„**: DOCX ë¬¸ì„œì—ì„œ ìš”êµ¬ì‚¬í•­ í…ìŠ¤íŠ¸ë¥¼ ê³„ì¸µì ìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.\n"
                "**2ë‹¨ê³„**: ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ Gemini AIë¥¼ ì‚¬ìš©í•˜ì—¬ ëª…í™•í•œ ìš”êµ¬ì‚¬í•­ ëª…ì„¸ë¡œ ì¬êµ¬ì„±í•©ë‹ˆë‹¤.")

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'extracted_df' not in st.session_state:
        st.session_state.extracted_df = pd.DataFrame()

    with st.sidebar:
        st.header("âš™ï¸ 1ë‹¨ê³„: ì¶”ì¶œ ì„¤ì •")
        business_code = st.text_input("ì‚¬ì—… ì½”ë“œ (ID ìƒì„±ìš©)", value="MFDS")

    uploaded_file = st.file_uploader("ë¶„ì„í•  .docx íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["docx"])

    if uploaded_file:
        extractor = AdvancedDocxExtractor(business_code=business_code)
        with st.spinner("1ë‹¨ê³„: ë¬¸ì„œ êµ¬ì¡° ë¶„ì„ ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘..."):
            file_bytes = io.BytesIO(uploaded_file.getvalue())
            st.session_state.extracted_df = extractor.process(file_bytes)

    if not st.session_state.extracted_df.empty:
        st.header("1ï¸âƒ£ ì¶”ì¶œ ê²°ê³¼")
        st.success(f"âœ… ì´ {len(st.session_state.extracted_df)}ê°œì˜ ìš”êµ¬ì‚¬í•­ í•­ëª©ì„ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
        st.dataframe(st.session_state.extracted_df)
        
        st.download_button(
            label="ğŸ“¥ ì¶”ì¶œ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ",
            data=st.session_state.extracted_df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig'),
            file_name=f"extracted_requirements_{business_code}.csv",
            mime="text/csv",
        )

        st.markdown("---")
        
        # --- Gemini ì—°ë™ UI ---
        st.header("2ï¸âƒ£ Gemini AIë¡œ ìš”êµ¬ì‚¬í•­ ì¬êµ¬ì„±")
        
        api_key = st.text_input("Gemini API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.", type="password", help="[Google AI Studio](https://aistudio.google.com/app/apikey)ì—ì„œ API í‚¤ë¥¼ ë°œê¸‰ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        if api_key:
            default_prompt = """ë‹¹ì‹ ì€ IT í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ì— ì œê³µëœ 'ì›ë³¸ ì¶”ì¶œ ë°ì´í„°'ëŠ” ë¬¸ì„œì—ì„œ ê¸°ê³„ì ìœ¼ë¡œ ì¶”ì¶œë˜ì–´ ë‹¤ì†Œ ì •ì œë˜ì§€ ì•Šì€ í…ìŠ¤íŠ¸ ëª©ë¡ì…ë‹ˆë‹¤.

            ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ë‹¤ìŒ ì§€ì¹¨ì— ë”°ë¼ ì´ ë°ì´í„°ë¥¼ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ 'ìš”êµ¬ì‚¬í•­ ëª…ì„¸'ë¡œ ì¬êµ¬ì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

            1.  **ê·¸ë£¹í™” ë° êµ¬ì¡°í™”**: ì—°ê´€ëœ í•­ëª©ë“¤ì„ ë…¼ë¦¬ì ì¸ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ê³ , ëª…í™•í•œ ì œëª©ê³¼ ë¶€ì œëª©ì„ ì‚¬ìš©í•˜ì„¸ìš”.
            2.  **ëª…ë£Œí•œ ë¬¸ì¥**: ê° ìš”êµ¬ì‚¬í•­ì€ ëª…í™•í•˜ê³  ê°„ê²°í•œ ë¬¸ì¥ìœ¼ë¡œ ë‹¤ì‹œ ì‘ì„±í•˜ì„¸ìš”. (ì˜ˆ: "~í•´ì•¼ í•œë‹¤", "~í•  ìˆ˜ ìˆì–´ì•¼ í•œë‹¤.")
            3.  **ì „ë¬¸ ìš©ì–´ ì‚¬ìš©**: ì ì ˆí•œ ê²½ìš°, 'ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­', 'ë¹„ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­', 'ë°ì´í„° ìš”êµ¬ì‚¬í•­' ë“± ì „ë¬¸ ìš©ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ë¥˜í•˜ì„¸ìš”.
            4.  **ì¶œë ¥ í˜•ì‹**: ìµœì¢… ê²°ê³¼ë¬¼ì€ ì „ë¬¸ê°€ê°€ ì‘ì„±í•œ ê²ƒì²˜ëŸ¼ ë³´ì´ëŠ” ê¹”ë”í•œ Markdown í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”. (ì˜ˆ: ì œëª©, ëª©ë¡, í…Œì´ë¸” ë“± í™œìš©)
            """
            
            user_prompt = st.text_area("LLMì—ê²Œ ë‚´ë¦´ ì§€ì‹œì‚¬í•­ (í”„ë¡¬í”„íŠ¸)", value=default_prompt, height=300)

            if st.button("ìš”êµ¬ì‚¬í•­ ì¬êµ¬ì„± ì‹¤í–‰ âœ¨", type="primary"):
                processor = GeminiProcessor(api_key=api_key)
                with st.spinner("Gemini AIê°€ ìš”êµ¬ì‚¬í•­ì„ ì¬êµ¬ì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    reconstructed_text = processor.reconstruct_requirements(st.session_state.extracted_df, user_prompt)
                
                st.subheader("ğŸ¤– Gemini ì¬êµ¬ì„± ê²°ê³¼")
                st.markdown(reconstructed_text)

if __name__ == '__main__':
    main()
